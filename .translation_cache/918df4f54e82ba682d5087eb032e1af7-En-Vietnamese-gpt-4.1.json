[
  "[Lỗi đoạn 1: ]",
  "[Lỗi đoạn 2: ]",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\n**tính hữu ích lâm sàng cao nhất** – điều này không phải lúc nào cũng là mô hình có độ chính xác cao nhất.\n\n**KHẢ THI**\n\nĐể đánh giá khả thi của thuật toán, cần xem xét:\n• Sự sẵn có và chất lượng dữ liệu\n• Chi phí triển khai\n• Thách thức khi triển khai\n• Mức độ tiếp nhận lâm sàng\n• Bảo trì theo thời gian\n\n**Sự sẵn có và chất lượng dữ liệu.**  \nDữ liệu là yếu tố quan trọng đối với bất kỳ thuật toán nào học từ dữ liệu. Khi đánh giá một mô hình AI, điều quan trọng là phải xem xét kỹ lưỡng dữ liệu được sử dụng cho huấn luyện, xác thực và kiểm thử.\n• Bao gồm việc thu thập, tiền xử lý và làm sạch dữ liệu\n• Quan trọng để biết liệu nhóm dân số hưởng lợi từ mô hình có được đại diện tốt trong dữ liệu huấn luyện hay không\n• Xem xét cách các giá trị nhãn được gán và ai là người gán các giá trị nhãn này\n• Minh bạch trong báo cáo dữ liệu và quá trình xử lý dữ liệu là điều thiết yếu để đánh giá bất kỳ mô hình nào\n\nCác câu hỏi khác cần suy nghĩ về dữ liệu:\n• Khả năng của dữ liệu là gì?\n• Dữ liệu có mới và cập nhật không?\n• Chúng ta có đang sử dụng dữ liệu từ năm năm trước để đánh giá một thủ thuật phẫu thuật mới chưa được triển khai rộng rãi trong khoảng thời gian của bộ dữ liệu không?\nBản quyền 2020 © Đại học Stanford 17\n• Dữ liệu thiếu được xử lý như thế nào?\n• Dữ liệu dọc có được xem xét không? Nếu có, việc mất dấu theo dõi được xử lý ra sao?\n\n**Khả thi của hành động:**\n• Nguồn lực cần thiết. Nếu bạn quyết định hành động, bạn có đủ nguồn lực và thiết bị để thực hiện hành động đó không?\n• Năng lực làm việc cần thiết. Hãy suy nghĩ về năng lực làm việc cần thiết để hành động.\n\nMột thành phần cần thiết để hiểu tính hữu ích là Đánh giá lâm sàng giải pháp AI.  \nDiễn đàn Quốc tế về Quản lý Thiết bị Y tế (IMDRF) đã phát triển một khung đánh giá lâm sàng được áp dụng toàn cầu, bao gồm cả bởi Cục Quản lý Thực phẩm và Dược phẩm Hoa Kỳ (FDA). Khung này được sử dụng để đánh giá rủi ro và tác động của các giải pháp AI, đồng thời chứng minh sự đảm bảo về an toàn, hiệu quả và hiệu suất.\n\n**Đánh giá lâm sàng:**\n1. **Liên kết lâm sàng hợp lệ:** Đề cập đến mức độ mà đầu ra của mô hình được chấp nhận về mặt lâm sàng hoặc có cơ sở vững chắc dựa trên một khung khoa học hoặc bằng chứng đã được thiết lập, và tương ứng chính xác với tình huống và điều kiện y tế thực tế được giải pháp AI xác định. Việc có một liên kết lâm sàng hợp lệ giữa đầu ra và đặc trưng là quan trọng nếu bạn mong đợi sự chấp nhận hoặc tiếp nhận lâm sàng.\n2. **Xác thực phân tích:** Mô hình có xử lý đúng dữ liệu đầu vào để tạo ra dữ liệu đầu ra đáng tin cậy, chính xác và nhất quán không? Loại đánh giá này đòi hỏi phải hiểu dữ liệu lâm sàng được sử dụng để phát triển mô hình và sự minh bạch trong báo cáo quá trình xử lý dữ liệu huấn luyện, cũng như hiểu rõ các biến đầu vào và đầu ra đã gán nhãn.\n3. **Xác thực lâm sàng:** Đo lường khả năng của giải pháp AI tạo ra đầu ra có ý nghĩa lâm sàng trong bệnh, tình huống hoặc điều kiện mục tiêu. “Có ý nghĩa lâm sàng” đề cập đến tác động mà giải pháp AI có thể có đối với sức khỏe cá nhân hoặc cộng đồng.\n\nViệc xác định độ chính xác và giá trị dự đoán của giải pháp AI là cần thiết, nhưng đánh giá thực sự về AI trong y tế là không dễ dàng. Các hệ thống đánh giá AI trong y tế hiện tại còn hạn chế – hoặc không tồn tại – trong việc ước tính giá trị ròng của mô hình. Ngoài ra, các ví dụ tốt về triển khai AI trên toàn hệ thống còn hạn chế. Do đó, các nhóm y tế phải dựa vào kinh nghiệm cá nhân và kinh nghiệm tập thể của đồng nghiệp để lấp đầy “khoảng trống” giữa bằng chứng hiện có và bằng chứng cần thiết về đánh giá AI.\n\nBản quyền 2020 © Đại học Stanford 18\n\n**TÀI LIỆU THAM KHẢO VÀ ĐỌC THÊM**\nFDA, U. 2019. “Khung pháp lý đề xuất cho việc sửa đổi phần mềm dựa trên trí tuệ nhân tạo/học máy (AI/ML) như một thiết bị y tế (SaMD).” FDA.\nShah NH, Milstein A, Bagley, PhD SC. Making Machine Learning Models Clinically Useful. JAMA. 2019;322(14):1351–1352. doi:10.1001/jama.2019.10306\n\n---\n\n**MODULE 3: TRIỂN KHAI AI**\n\n**MỤC TIÊU HỌC TẬP**\n1. Hiểu bốn thành phần của triển khai AI\n2. Mô tả vai trò của giới học thuật trong phát triển và triển khai giải pháp AI trong y tế\n3. Hiểu các khoản đầu tư cần thiết để tích hợp giải pháp AI vào môi trường chăm sóc, từ nhà nghiên cứu đến bác sĩ lâm sàng và hệ thống y tế\n4. Biết những thách thức lớn cần vượt qua để triển khai thành công giải pháp AI vào cung cấp dịch vụ y tế, bao gồm cân nhắc về tác hại có thể dự đoán hoặc dự định\n\n**TRIỂN KHAI AI**\n\nAI trong y tế phát triển chậm hơn vì liên quan đến tính mạng con người, do đó các quy định, chính sách và tiêu chuẩn đặt ra yêu cầu cao hơn cho phát triển và triển khai sản phẩm. Sự hào hứng với AI trong y tế đã bị lu mờ bởi con đường đầy thách thức để đưa các giải pháp này vào chăm sóc lâm sàng thường quy.\n\n**Các thách thức khi triển khai:**\n• Thiếu sự đồng thuận từ các bên liên quan cần thiết\n• Thiếu bằng chứng về tính hữu ích lâm sàng\n• Thiếu nguồn lực và chuyên môn về triển khai AI\n• Việc sử dụng dữ liệu lâm sàng thứ cấp vốn được tạo ra và quản lý trong hệ thống y tế với mục đích chính là hỗ trợ chăm sóc và tạo hồ sơ thanh toán, chứ không phải để phục vụ nghiên cứu lâm sàng hoặc phân tích thứ cấp\n\nBản quyền 2020 © Đại học Stanford 19\n\nCho đến nay, hầu hết các tài liệu và đánh giá về giải pháp AI trong y tế tập trung vào bằng chứng về khả năng dự đoán và độ chính xác của giải pháp AI. Gần đây, có sự quan tâm ngày càng tăng đến việc đánh giá tác động sâu hơn của các ứng dụng AI trong y tế, bao gồm các vấn đề về thiên lệch và công bằng giữa các nhóm dân số.\n\nKhi nghĩ đến việc đưa một giải pháp AI vào môi trường y tế, chúng ta cần cân nhắc một khung tổng thể để chuyển đổi sản phẩm vào hệ thống cung cấp dịch vụ – và nhiều bên liên quan sẽ tương tác với sản phẩm cuối cùng. Mô hình AI chỉ là một thành phần trong vòng đời sản phẩm tổng thể (TPLC) và tất cả các thành phần đều cần được hiểu và đánh giá khi triển khai.\n\n**TPLC bao gồm:**\n• Lựa chọn và quản lý dữ liệu\n• Huấn luyện và điều chỉnh mô hình\n• Xác thực mô hình\n\nKhi bạn đã hoàn thành phần đầu tiên “Phát triển mô hình AI”, bạn chuyển sang Mô hình AI sản xuất, hay “Mô hình đã triển khai” – mô hình này liên tục nhận dữ liệu mới (hoặc dữ liệu trực tiếp) và liên tục được giám sát để đánh giá an toàn và hiệu suất.\n\n**Một số câu hỏi thực tiễn bạn có thể (hoặc nên) đặt ra trước khi triển khai:**\n1. **Câu hỏi nghiên cứu, liên quan đến Tính hữu ích lâm sàng.** Câu hỏi lâm sàng là gì và tôi có thể trả lời câu hỏi đó bằng một sản phẩm AI không? Đó có phải là câu hỏi có thể giải quyết với dữ liệu tôi có và độ chính xác của các mô hình tôi xây dựng không?\nBản quyền 2020 © Đại học Stanford 20\n\n2. **Sự tham gia của các bên liên quan – Người dùng dự kiến.** Ai sẽ là người sử dụng đầu ra của mô hình và họ muốn xem kết quả như thế nào? Kết quả từ mô hình có cần được hiển thị cho bác sĩ lâm sàng tại điểm chăm sóc, cho ban quản lý bệnh viện để đánh giá tái nhập viện, hay cho công ty bảo hiểm để xác định bệnh nhân có chi phí cao không? Tất cả các bên liên quan đã đánh giá cả dữ liệu đầu vào và đầu ra dự kiến chưa?\n\n3. **Dữ liệu huấn luyện.** Nguồn dữ liệu tôi sẽ dùng để huấn luyện mô hình là gì và tôi sẽ lấy dữ liệu này ở đâu? Dữ liệu này có mới không và chất lượng ra sao? Dữ liệu của bạn cần được cập nhật hàng tuần, hàng đêm hay hàng giờ để đưa ra dự đoán? Phân bố dân số của dữ liệu này như thế nào và kết quả quan tâm có được đại diện tốt trong dữ liệu này và có đại diện cho dân số áp dụng không?\n\n4. **Chi phí triển khai – Thiết lập hệ thống.** Bạn sẽ cần thiết lập hệ thống như thế nào để chạy mô hình? Hệ thống bạn phát triển mô hình có tương thích với hệ thống bạn sẽ sử dụng mô hình không? Bạn có thể thiết lập tất cả các cài đặt cần thiết trong hệ thống thực tế không?\n\n5. **Khả thi – Tiếp nhận lâm sàng.** Làm thế nào để bạn đưa đầu ra mô hình trở lại quy trình làm việc một cách chính xác và theo thời gian thực? Đầu ra của bạn sẽ được tích hợp vào hệ thống EHR hay phải hiển thị song song với hệ thống EHR? Đầu ra mô hình của bạn sẽ làm gián đoạn quy trình lâm sàng như thế nào? Bạn có nhận được sự ủng hộ đáng kể từ người dùng cuối và họ có sẵn sàng là người tiên phong triển khai hệ thống không?\n\n6. **Bảo trì theo thời gian.** Ai sẽ chịu trách nhiệm giám sát và cập nhật liên tục sản phẩm AI? Dữ liệu mới sẽ được thêm vào như thế nào hoặc mô hình sẽ được huấn luyện lại khi nào? Nếu phát hiện thiên lệch hoặc hậu quả không mong muốn thì sao? Ai sẽ chịu trách nhiệm cập nhật và bảo trì sản phẩm?\n\nNhững câu hỏi này cần được đánh giá trước khi triển khai giải pháp AI.\n\n**Lộ trình triển khai có bốn thành phần cơ bản:**\n1. Thiết kế và phát triển sản phẩm AI – xác định đúng vấn đề cần giải quyết.\n2. Đánh giá và xác thực sản phẩm AI, bao gồm nhiều lần lặp lại. Mô hình thường được đánh giá trước tiên bằng dữ liệu hồi cứu.\n3. Phổ biến và mở rộng sản phẩm AI\n4. Giám sát và bảo trì liên tục giải pháp AI để đảm bảo an toàn và hiệu quả.\n\nBản quyền 2020 © Đại học Stanford 21\n\n**THIẾT KẾ VÀ PHÁT TRIỂN**\n\nThiết kế và phát triển sản phẩm bắt đầu từ vấn đề: Đây có phải là vấn đề quan trọng và có thể trả lời bằng dữ liệu và mô hình AI hiện có không? Bước này cần được hoàn thành trước khi triển khai.\n\nViệc xác định và mô tả vấn đề cần giải quyết bằng giải pháp AI là rất quan trọng, đồng thời đánh giá xem vấn đề đó có thể (hoặc xứng đáng) được giải quyết bằng AI không; nghĩa là xác định một đầu ra mô hình có thể hành động và sẽ tác động đến cung cấp dịch vụ hoặc kết quả của bệnh nhân.\n\nCần hiểu rõ kết quả bạn xác định trong bối cảnh hệ thống y tế. Cũng cần nhớ rằng định nghĩa y khoa thay đổi theo thời gian. Không có định nghĩa y khoa nào là bất biến.\n\nKhi thiết kế giải pháp AI, cần nhớ rằng giải pháp phải linh hoạt, có thể thích nghi với thay đổi định nghĩa, thay đổi công nghệ, thay đổi loại dữ liệu hoặc thay đổi hệ thống cung cấp dịch vụ y tế. Môi trường y tế không phải là lĩnh vực tĩnh; hướng dẫn và tiêu chuẩn chăm sóc lâm sàng luôn thay đổi. Thuật toán AI phải đủ linh hoạt để thích ứng với các chức năng hoặc thay đổi mới này theo thời gian với nỗ lực tối thiểu.\n\nCuối cùng, cần nhớ rằng với bất kỳ thay đổi nào, sẽ cần có đánh giá mã nguồn mới, chỉ số hiệu suất mô hình mới và thiết lập năng lực giám sát mới.\n\nTrong thành phần thiết kế và phát triển, cần đánh giá sự tham gia của các bên liên quan. Quan trọng là phải hiểu người dùng dự kiến, quy trình làm việc hiện tại của họ và cách đầu ra của mô hình sẽ được chuyển giao cho người dùng này để hành động. Mỗi người dùng dự kiến khác nhau sẽ cần một lộ trình hoặc bảng điều khiển riêng để nhận đầu ra mô hình.\n\nVí dụ về khó thở cấp tính, ai là các bên liên quan của bạn?\n• Nhóm CNTT – bạn cần lấy dữ liệu theo thời gian thực\n• Bác sĩ lâm sàng – bạn cần biết họ muốn nhận dữ liệu như thế nào và ở đâu\n• Lãnh đạo tổ chức – bạn có nhận được sự ủng hộ để triển khai sản phẩm AI trong hệ thống y tế không\n• Lãnh đạo tài chính – ai sẽ chi trả chi phí vận hành\n• Chuyên gia giao diện người dùng – ai sẽ thiết kế giao diện cho đầu ra mô hình của bạn\n• Chuyên gia hệ thống EHR – bạn sẽ tích hợp kết quả với hệ thống hiện có như thế nào\n• Và còn nhiều người dùng khác\n\nBản quyền 2020 © Đại học Stanford 22\n\nViệc xác định đúng các bên liên quan và có sự tham gia của họ trong thiết kế, phát triển sản phẩm AI là chìa khóa để triển khai thành công.\n\n**Dữ liệu huấn luyện** – Nguồn dữ liệu, loại dữ liệu và sự sẵn có của dữ liệu là cốt lõi của bất kỳ sản phẩm AI nào, và việc biết chất lượng, độ tin cậy, tính đại diện và cập nhật của dữ liệu là điều bắt buộc khi triển khai AI.\n\nSản phẩm AI có thể sử dụng 3 nguồn dữ liệu khác nhau:\n1. Nguồn dữ liệu nội bộ\n2. Nguồn dữ liệu bên ngoài. Đây là trường hợp một nhóm ở một nơi làm việc với dữ liệu từ nơi khác. Có rất ít kiểm soát về chất lượng và thiếu dữ liệu bên ngoài, không giống như dữ liệu nội bộ, trừ khi bạn thực hiện thỏa thuận chia sẻ dữ liệu – điều này có thể tốn nhiều công sức và khó khăn.\n3. Nguồn dữ liệu công khai. Nhiều sản phẩm AI được phát triển từ nguồn dữ liệu công khai, ví dụ bộ dữ liệu MIMIC-III, là cơ sở dữ liệu chăm sóc tích cực miễn phí.\n\n---\n\n*Lưu ý: Do độ dài văn bản, bản dịch này có thể cần chia nhỏ hoặc hiệu chỉnh thêm tùy theo mục đích sử dụng. Nếu bạn cần tiếp tục phần còn lại hoặc cần bản dịch ngắn gọn hơn, hãy cho tôi biết!*",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\nMột lợi thế của việc sử dụng các nguồn dữ liệu công khai là các sản phẩm AI được phát triển và triển khai với các bộ dữ liệu này có thể được các nhà khoa học khác đánh giá và tái tạo – qua đó tăng độ tin cậy và tác động của chúng trong lĩnh vực này. Dù sản phẩm AI được phát triển từ dữ liệu nội bộ, bên ngoài hay công khai, mỗi nguồn dữ liệu đều có những cơ hội và thách thức riêng liên quan đến việc sử dụng. Khi thiết kế và phát triển một sản phẩm AI, điều quan trọng là phải cân nhắc bối cảnh và nguồn tài trợ (Chi phí Triển khai – Thiết lập Hệ thống) của câu hỏi ban đầu, vì điều này sẽ thúc đẩy hoặc có thể cản trở việc triển khai. Các sản phẩm AI bắt nguồn từ ngành công nghiệp thường có khả năng thương mại hóa và lan tỏa cao. • Ngành công nghiệp thường buộc phải hợp tác với học thuật hoặc các ngành khác để có được dữ liệu cần thiết cho việc huấn luyện và phát triển mô hình của họ. Do đó, việc hiểu rõ loại dữ liệu và nguồn dữ liệu từ các sản phẩm do ngành công nghiệp dẫn dắt là rất quan trọng, đặc biệt là tính đại diện của chúng đối với quần thể mà sản phẩm sẽ được áp dụng. • Trong học thuật, các nhà khoa học đầu ngành thường suy nghĩ về các câu hỏi đổi mới, phương pháp đổi mới và thường bắt đầu với một câu hỏi nghiên cứu cụ thể. Họ có quyền truy cập vào dữ liệu lâm sàng và chuyên môn lâm sàng. Với môi trường hợp tác trong học thuật, các nhóm này là chuyên gia trong việc phát triển các nhóm đa ngành và dễ dàng xây dựng, duy trì các nhóm này. Tuy nhiên, học thuật gặp khó khăn trong việc thu hút và giữ chân chuyên gia kỹ thuật – họ thường không thể cạnh tranh với mức lương của ngành công nghiệp – và khả năng mở rộng hiệu quả thường không phải là thế mạnh. • Các sản phẩm AI cũng có thể bắt nguồn từ các công ty khởi nghiệp. Sản phẩm AI từ các start-up thường tự tài trợ, rất hiệu quả và tập trung vào một sản phẩm hoặc chuyên môn duy nhất. Thường thì, khi các công ty khởi nghiệp có một sản phẩm tốt, họ sẽ được các công ty lớn hơn mua lại, và khi đó sản phẩm của họ có thể được lan tỏa và mở rộng quy mô. • Các tổ chức từ thiện thường làm việc trên các lĩnh vực mục tiêu và hợp tác. Họ có thể tài trợ cho việc phát triển sản phẩm nhằm giải quyết vấn đề an toàn bệnh nhân trên nhiều bối cảnh khác nhau. Đôi khi, tổ chức từ thiện sẽ hợp tác với học thuật, ngành công nghiệp hoặc chính phủ khi cần thiết để phát triển các sản phẩm mà họ quan tâm. Việc thiết kế và phát triển sản phẩm AI có thể bắt đầu ở nhiều bối cảnh khác nhau, bao gồm ngành công nghiệp, học thuật, start-up, tổ chức từ thiện hoặc chính phủ. Mỗi bối cảnh đều có một tập hợp các thách thức và cơ hội riêng cho việc triển khai.\n\nĐÁNH GIÁ VÀ XÁC THỰC\n\nThành phần thứ hai của Triển khai AI là đánh giá và xác thực sản phẩm AI. Trước khi triển khai, sản phẩm AI ban đầu phải trải qua các đánh giá in silico nghiêm ngặt, bao gồm: • Điều tra tính hữu ích lâm sàng (hoặc giá trị ròng) • Giá trị thống kê • Giá trị kinh tế của mô hình AI\n\nTính hữu ích của giải pháp AI (tính hữu ích lâm sàng) có lẽ là tiêu chí quan trọng nhất cần đánh giá khi xem xét triển khai giải pháp AI trong chăm sóc y tế. Tính hữu ích của một giải pháp AI liên quan đến khả năng áp dụng và tác động của nó đối với hệ thống y tế. Các yếu tố có thể ảnh hưởng đến tính hữu ích lâm sàng: • Ai là người cần thực hiện hành động • Thời gian dẫn được cung cấp bởi dự đoán • Sự tồn tại của hành động (hoặc liệu pháp) giảm thiểu • Khả năng can thiệp • Hậu cần và chi phí của can thiệp, các ưu đãi, v.v.\n\nĐể hiểu tính hữu ích lâm sàng của bất kỳ giải pháp AI nào, bạn phải hỏi: Nhiệm vụ chính của mô hình là gì và ai là các bên liên quan chính, điều này được gọi là khung cặp kết quả-hành động.\n\nTính hữu ích lâm sàng liên quan đến việc sản phẩm AI có thể chứng minh được mức cải thiện quy trình làm việc thực tế hoặc cải thiện chăm sóc lâm sàng và kết quả bệnh nhân như thế nào. Tính hữu ích lâm sàng phải được so sánh với dữ liệu hiệu suất cơ sở – bạn phải chứng minh rằng việc áp dụng sản phẩm của bạn là hữu ích, một lần nữa là về mặt chăm sóc lâm sàng (bao gồm hiệu quả lâm sàng) và kết quả bệnh nhân so với dữ liệu hiệu suất cơ sở hiện tại.\n\nGiá trị ròng liên quan đến mức độ hữu ích của giải pháp AI dựa trên các ràng buộc hiện hữu trong môi trường chăm sóc. Các phương pháp như phân tích đường cong quyết định có thể định lượng lợi ích ròng của việc sử dụng một mô hình để hướng dẫn các hành động tiếp theo, dựa trên chi phí của các hành động thay thế, lợi ích tương ứng của chúng và các chỉ số hiệu suất mô hình khác nhau. Giá trị ròng nên được xem xét ngay từ đầu, để có một mô hình hữu ích ở tuyến đầu. Cần cân nhắc chi phí và lợi ích của các hành động được kích hoạt bởi sản phẩm AI để đưa ra quyết định tốt hơn.\n\nGiá trị kinh tế đặt ra câu hỏi: Có thực sự có lợi ích ròng từ khoản đầu tư này không, hoặc chi phí tích hợp vận hành là bao nhiêu. Để làm được điều này, bạn phải nghĩ đến tiết kiệm chi phí, tăng hoàn trả, hoặc tăng hiệu quả liên quan đến sản phẩm AI.\n\nNăng lực làm việc đề cập đến khả năng của một hệ thống đáp ứng với một dự đoán. Năng lực làm việc là một thành phần quan trọng của đánh giá AI cần được đánh giá trước khi xem xét triển khai giải pháp AI trong chăm sóc sức khỏe. Trong quá trình đánh giá này, cũng cần xem xét tính hữu ích tối ưu (thực hiện hành động đối với những người sẽ hưởng lợi nhiều nhất). Tính hữu ích tối ưu cực kỳ quan trọng khi dự đoán việc sử dụng các nguồn lực khan hiếm. Giá trị ròng và năng lực làm việc thường bị bỏ qua khi các sản phẩm AI được báo cáo trong tài liệu khoa học, tuy nhiên chúng rất cần thiết để điều tra trước khi triển khai sản phẩm AI trong môi trường chăm sóc sức khỏe.\n\nMột khía cạnh khác của thành phần đánh giá và xác thực triển khai là giá trị thống kê. Điều này bao gồm các chỉ số hiệu suất như độ chính xác, độ tin cậy, độ chính xác, độ nhớ và hiệu chuẩn. Giá trị thống kê của một mô hình là rất quan trọng và thường được báo cáo như một dấu hiệu của hiệu suất mô hình. Tuy nhiên, hiện thiếu các hướng dẫn cho các mức hiệu suất rời rạc. Thuật toán chính xác nhất thường không nhất thiết là thuật toán tốt nhất để triển khai. Giá trị thống kê là một thành phần của triển khai. Việc xác định các tiêu chuẩn và chỉ số hiệu suất thuật toán ngày càng trở nên quan trọng và một khái niệm mới nổi cho rằng nên có một thành phần tuân thủ hoặc phù hợp trong đánh giá hiệu suất của các sản phẩm AI.\n\nXÁC THỰC SẢN PHẨM\n\nKhi triển khai, cần xác định sự tham gia của con người. Liệu con người có tham gia vào vòng lặp hay sản phẩm AI sẽ hoạt động tự động và xác định các thông tin có thể hành động? Đây là một trong những khía cạnh quan trọng nhất trong việc đánh giá và xác thực sản phẩm AI trước khi tích hợp thực tế vào chăm sóc lâm sàng. Ở chế độ im lặng, sản phẩm AI được triển khai tại điểm chăm sóc và dự đoán được thực hiện theo thời gian thực nhưng không có hành động nào được thực hiện dựa trên các dự đoán đó. Các dự đoán được cung cấp cho người dùng dự kiến, người sau đó đánh giá xem dự đoán có tốt hay không hoặc có thể được sử dụng để cải thiện quy trình làm việc hoặc kết quả bệnh nhân hay không. Điều này rất quan trọng để hoàn thiện quy trình làm việc và cấu hình sản phẩm, cũng như xác thực theo thời gian thực, tiến trình của một sản phẩm AI.\n\nĐối với tích hợp vào chăm sóc, một bước quan trọng trong lộ trình này là xem xét tương tác giữa con người và máy móc:\n1. Xác định vấn đề lâm sàng. Điều quan trọng là xác định một vấn đề phù hợp để giải quyết bằng thuật toán AI.\n2. Suy nghĩ về tương tác giữa con người và máy móc. Đánh giá im lặng rất quan trọng để đảm bảo người dùng – hoặc người dùng dự kiến của đầu ra mô hình – đang diễn giải đầu ra mô hình một cách chính xác và đầu ra được áp dụng phù hợp và cho đúng đối tượng.\n\nKhi đánh giá tương tác giữa con người và máy móc, chúng ta cần suy nghĩ về cách quy trình làm việc lâm sàng được thiết kế và cách nó sẽ triển khai sản phẩm AI. Ngoài ra, bạn cần kiểm tra khả năng sử dụng giao diện và tác động của sản phẩm đối với việc ra quyết định lâm sàng, bao gồm các vấn đề pháp lý và đạo đức của sản phẩm AI của bạn. Chế độ im lặng là một khía cạnh quan trọng, mặc dù thường bị bỏ qua trong triển khai. Có một khoảng cách lớn giữa AI được phát triển cho nghiên cứu và AI được triển khai vào môi trường chăm sóc lâm sàng. Do đó, tích hợp lâm sàng có thể là phần khó khăn nhất của quá trình triển khai.\n\nMột số cân nhắc chính cho việc tích hợp lâm sàng của sản phẩm AI bao gồm (1) Cân nhắc về cấu trúc, và (2) Cân nhắc về hợp tác.\n\nCân nhắc về cấu trúc:\n1. Năng lực tổ chức\n2. Năng lực nhân sự\n3. Cân nhắc về chi phí, doanh thu và giá trị\n   a. Chi phí ban đầu\n   b. Lợi tức đầu tư dự kiến\n   c. Giá trị liên quan đến triển khai AI\n4. Giám sát an toàn và hiệu quả\n5. An ninh mạng và quyền riêng tư\n\nCân nhắc về hợp tác:\n1. Đồng thuận của các bên liên quan\n2. Đảm bảo cam kết từ lãnh đạo tổ chức\n3. Xác định lãnh đạo\n4. Thu hút các bên liên quan\n5. Xác định các mốc, chỉ số và kết quả để đo lường sự triển khai thành công\n\nTích hợp lâm sàng, mặc dù chỉ là một dấu mốc nhỏ trên lộ trình, có thể là trở ngại lớn nhất cần vượt qua để triển khai AI thành công. Công nghệ trong môi trường nghiên cứu khác biệt rất nhiều so với môi trường bệnh viện. Cần có nỗ lực đáng kể và đầu tư hạ tầng để tích hợp các sản phẩm AI vào hệ thống thời gian thực tại điểm chăm sóc. Cần xem xét các nền tảng dữ liệu liên quan, môi trường nền tảng và công nghệ cụ thể cần thiết để chạy các mô hình tại điểm chăm sóc. Do thiếu khả năng tương tác và tiêu chuẩn dữ liệu, khi một tổ chức khác muốn triển khai một sản phẩm đã được phát triển, họ cũng phải chịu cùng chi phí vì phải trải qua cùng quá trình thu thập, làm sạch dữ liệu, đánh giá và xác thực mô hình như phát triển sản phẩm ban đầu. Do chi phí triển khai thực tế các sản phẩm AI, việc tích hợp vận hành mô hình nên được cân nhắc kỹ lưỡng.\n\nPHỔ BIẾN VÀ MỞ RỘNG\n\nGiai đoạn thứ ba của triển khai là phổ biến và mở rộng sản phẩm. Phổ biến và mở rộng sản phẩm diễn ra sau khi bạn giải quyết được môi trường chăm sóc sức khỏe địa phương. Có ba loại hệ thống khác nhau cần xem xét khi phát triển các phương thức triển khai:\n• Tích hợp hoàn toàn vào hệ thống EHR\n• Tích hợp một phần vào hệ thống EHR\n• Các mô hình độc lập\n\nĐể phổ biến các sản phẩm AI, chúng phải có khả năng tiếp nhận dữ liệu khác nhau từ các hệ thống khác nhau và hỗ trợ triển khai tại chỗ và trên đám mây. Một sản phẩm được thiết kế tốt sẽ có thể thích ứng với hệ thống Epic, Cerner, hoặc bất kỳ hệ thống EHR tự phát triển nào khác. Hầu hết các module hiện nay là độc lập. Điều quan trọng là phải hiểu rằng phần lớn các sản phẩm trên thị trường ban đầu được phát triển trong môi trường học thuật. Trong môi trường học thuật, các sản phẩm hiếm khi được phổ biến và lan tỏa ở quy mô lớn, do đó, chúng thường kết hợp với các đối tác công nghiệp để phát triển sản phẩm hoàn chỉnh. Sản phẩm được cấp phép bên ngoài, mở rộng quy mô và phổ biến thông qua các tổ chức thương mại. Sản phẩm được tài trợ hoặc bởi các nhà đầu tư mạo hiểm, hoặc chính phủ trong môi trường học thuật chăm sóc sức khỏe.\n\nGIÁM SÁT VÀ BẢO TRÌ\n\nKhi một sản phẩm AI được triển khai, cần có một kế hoạch để đảm bảo sản phẩm sẽ được giám sát và bảo trì liên tục. Điều này bao gồm cập nhật kiến trúc định kỳ, bổ sung dữ liệu huấn luyện mới, và có thể cập nhật hàng năm và/hoặc không định kỳ khi các tệp tham chiếu của ngành thay đổi. Hiệu suất mô hình có thể suy giảm ngay trong cùng một hệ thống chăm sóc sức khỏe theo thời gian khi, ví dụ, môi trường chăm sóc lâm sàng thay đổi, dân số bệnh nhân thay đổi, hoặc tỷ lệ phơi nhiễm hoặc kết quả thay đổi. Một mã chẩn đoán mới cho một bệnh quan tâm hoặc một định nghĩa lâm sàng mới cho một kết quả quan tâm có thể xuất hiện. Điều này sẽ yêu cầu cập nhật sản phẩm AI để tính đến những thay đổi này. Ngoài ra còn có các cập nhật nhỏ cho mô hình hoặc sửa lỗi cần thực hiện vào các thời điểm không định kỳ. Có nhiều phương pháp được sử dụng để tính đến các thay đổi hệ thống đối với dữ liệu nguồn. Các phương pháp này bao gồm từ việc tái tạo hoàn toàn mô hình theo định kỳ đến hiệu chỉnh lại mô hình bằng nhiều phương pháp khác nhau. Tuy nhiên, tần suất và khối lượng của những thay đổi này chưa được chuẩn hóa. Các cải tiến lớn và nhỏ cho mô hình hoặc các chức năng mới để đáp ứng nhu cầu lâm sàng phát triển là rất quan trọng.\n\nTHÁCH THỨC CỦA TRIỂN KHAI\n\nTriển khai là một quá trình phức tạp và có nhiều vấn đề cần được giải quyết trước, trong và sau khi triển khai một sản phẩm AI trong hệ thống chăm sóc sức khỏe. Một thách thức quan trọng trong triển khai AI là thách thức về đạo đức:\n• Bảo mật dữ liệu và quyền riêng tư của bệnh nhân: bệnh nhân có thể không biết dữ liệu của họ đang được sử dụng, chia sẻ hoặc bán cho việc phát triển sản phẩm AI. Ở một số môi trường chăm sóc sức khỏe, có thể được miễn trừ đồng ý.\n• Mẫu huấn luyện không đại diện cho quần thể dự kiến: Vấn đề này càng trầm trọng hơn vì hầu hết các sản phẩm AI không minh bạch về mẫu huấn luyện của họ và thường không báo cáo phân bố nhân khẩu học của dữ liệu huấn luyện.\n• Minh bạch: Các chi tiết về chỉ số đánh giá và xác thực thường không được báo cáo.\n• Khả năng tương tác: Nếu một hệ thống...\n\n---\n\n(Lưu ý: Đoạn cuối của văn bản gốc bị cắt ngang, nếu bạn cần dịch tiếp phần còn lại, vui lòng cung cấp thêm nội dung.)",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\nNếu muốn triển khai một sản phẩm được phát triển ở một môi trường khác, họ có thể sẽ phải chịu lại cùng một chi phí vì do vấn đề tương tác, hầu hết các hệ thống không thể trao đổi mã một cách liền mạch. Các tiêu chuẩn mới đang xuất hiện, như SMART và FHIR.  \n- FHIR là một tiêu chuẩn để trao đổi dữ liệu chăm sóc sức khỏe, được xuất bản bởi HL7  \n- Khung ứng dụng SMART kết nối các ứng dụng bên thứ ba với dữ liệu EHR, cho phép các ứng dụng khởi chạy từ bên trong hoặc bên ngoài giao diện người dùng của hệ thống EHR  \n• Thiếu tiêu chuẩn thực hành tốt nhất cho các chỉ số hiệu suất: Hiện không có các chỉ số hiệu suất tiêu chuẩn cho các mô hình này.  \n• Khoa học \"ẩn\": Khoa học ẩn đề cập đến các nghiên cứu được phát triển và phổ biến mà không qua đánh giá ngang hàng nghiêm ngặt. Trong ngành công nghiệp, khoa học ẩn là phổ biến khi các công ty cố gắng bảo vệ bí mật thương mại hoặc tránh bị giám sát học thuật. Điều này đặc biệt đúng với AI và chăm sóc sức khỏe, nhất là khi nhiều sản phẩm AI được phát triển bởi các công ty. Các mô hình phát triển trong nghiên cứu hiếm khi được chuyển giao vào thực hành lâm sàng, do đó rất khó để đánh giá hiệu quả lâm sàng và kinh tế thực sự của chúng.  \nDự đoán nhiễm trùng huyết là một ví dụ điển hình để minh họa cách các mô hình học máy cho dự đoán nhiễm trùng huyết có thể được chuyển giao vào quy trình chăm sóc lâm sàng:  \n• Sepsis Watch: Sản phẩm đã được xác thực nội bộ (theo hướng tiến cứu) thông qua một thử nghiệm lâm sàng đã đăng ký và sau đó được cấp phép thương mại vào năm 2019  \n• Dascena Insight: Sản phẩm đã được xác thực bên ngoài trong một thử nghiệm lâm sàng tiến cứu và hồi cứu trên 6 viện để đánh giá khả năng tổng quát hóa.  \nBản quyền 2020 © Đại học Stanford 29  \n• TREW Score: Được phát triển bằng bộ dữ liệu công khai (MIMIC-II). TREW Score đã được triển khai tại nhiều bệnh viện.  \nCó nhiều thuật toán tương tự khác; Có thể đặt câu hỏi, tại sao lại có nhiều thuật toán dự đoán cùng một vấn đề và thuật toán nào là tốt nhất để triển khai? Điều quan trọng là phải suy nghĩ về tất cả những thách thức liên quan đến triển khai mà chúng ta đã thảo luận và cách đánh giá hoặc so sánh các sản phẩm AI này.  \n\nTRÍCH DẪN VÀ ĐỌC THÊM  \nGupta, A., T. Liu, và S. Shepherd. 2020. “Clinical decision support system to assess the risk of sepsis using Tree Augmented Bayesian networks and electronic medical record data.” Health Informatics J 26(2): 841-61.  \nSendak, M. P., W. Ratliff, D. Sarro, E. Alderton, J. Futoma, M. Gao, M. Nichols, M. Revoir, F. Yashar, C. Miller, K. Kester, S. Sandhu, K. Corey, N. Brajer, C. Tan, A. Lin, T. Brown, S. Engelbosch, K. Anstrom, M. C. Elish, K. Heller, R. Donohoe, J. Theiling, E. Poon, S. Balu, A. Bedoya, và C. O'Brien. 2020. “Real-World Integration of a Sepsis Deep Learning Technology Into Routine Clinical Care: Implementation Study.” JMIR Med Inform 8(7): e15182.  \nSendak, M.P., D’Arcy, J., Kashyap, S., Gao, M., Nichols, M., Corey, K., Ratliff, W. và Balu, S., 2020. A path for translation of machine learning products into healthcare delivery. European Medical Journal Innovations.  \nShah NH, Milstein A, Bagley, PhD SC. Making Machine Learning Models Clinically Useful. JAMA. 2019;322(14):1351–1352. doi:10.1001/jama.2019.10306  \nTopiwala, R., K. Patel, J. Twigg, J. Rhule, và B. Meisenberg. 2019. “Retrospective Observational Study of the Clinical Performance Characteristics of a Machine Learning Approach to Early Sepsis Identification.” Crit Care Explor 1(9): e0046.  \nBản quyền 2020 © Đại học Stanford 30  \n\nMODULE 4: ĐÁNH GIÁ HẠ LƯU CỦA AI TRONG CHĂM SÓC SỨC KHỎE: THIÊN LỆCH VÀ CÔNG BẰNG  \nMỤC TIÊU HỌC TẬP  \n1. Tổng quan về thiên lệch và công bằng trong các giải pháp AI cho y tế  \n2. Hiểu các loại thiên lệch khác nhau trong giải pháp AI y tế  \n3. Mô tả công bằng thuật toán  \n4. Xác định các giải pháp để giải quyết thiên lệch và công bằng trong AI  \n\nTHIÊN LỆCH TRONG GIẢI PHÁP AI  \nGần đây, các báo cáo đã đặt câu hỏi liệu các giải pháp AI trong chăm sóc sức khỏe có thực sự duy trì sự phân biệt đối xử nếu được huấn luyện trên dữ liệu lịch sử — vốn thường không đại diện tốt cho các nhóm dân số rộng lớn hơn. Thường thì các mô hình AI được huấn luyện bằng dữ liệu lịch sử hoặc hồi cứu, vốn thường xuất phát từ các trung tâm y tế học thuật giàu có, có thể không bao gồm tất cả các nhóm dân số, đặc biệt là các nhóm đa dạng mà AI sẽ được áp dụng. Các mô hình AI chỉ huấn luyện trên các dữ liệu như vậy có thể tiếp tục duy trì bất bình đẳng và không chứng minh được tính hợp lệ bên ngoài ở các cộng đồng bệnh nhân rộng lớn hơn. Điều này có thể do thiếu sự đa dạng trong dữ liệu huấn luyện, thiếu hiểu biết về cách bệnh có thể biểu hiện và tiến triển ở các nhóm dân số khác nhau, và thiếu hiểu biết của con người về các hậu quả và thiên lệch tiềm ẩn trong các giải pháp AI.  \nCông bằng và thiên lệch trong giải pháp AI có thể là vấn đề lớn hơn ở các quốc gia có sự chênh lệch sức khỏe đáng kể dựa trên nhân khẩu học bệnh nhân, như Hoa Kỳ. Do đó, khi các công cụ này lan rộng trong các môi trường lâm sàng, điều quan trọng là phải suy nghĩ và hiểu các thiên lệch nhân khẩu học tiềm ẩn trong phát triển và triển khai mô hình.  \n\nVí dụ về suy tim:  \nKhông lâu trước đây, chúng ta không biết rằng các triệu chứng nhồi máu cơ tim ở phụ nữ khác với nam giới, dẫn đến sự khác biệt về tỷ lệ tử vong do tim mạch giữa hai giới. Vấn đề ở đây là mô hình được phát triển dựa trên triệu chứng của nam giới nên có thể rất chính xác trong việc nhận diện nam giới có triệu chứng nhồi máu cơ tim, nhưng lại không hiệu quả với nữ giới, những người có triệu chứng khác. Độ chính xác dự đoán, khi phân tích với kết quả lâm sàng thực tế, sẽ giảm ở phụ nữ nhưng không giảm ở nam giới.  \n\nVí dụ về cơ sở dữ liệu gen:  \nBản quyền 2020 © Đại học Stanford 31  \nCác cơ sở dữ liệu gen được sử dụng rộng rãi trong cộng đồng nghiên cứu cho thấy sự thiên lệch chủng tộc lớn trong các mẫu gen thu thập được. Những cơ sở dữ liệu này là trung tâm của y học chính xác, nơi khả năng xác định một biến thể gen có gây bệnh hay không phụ thuộc một phần vào độ tin cậy khi gán nhãn biến thể là gây bệnh. Nghiên cứu cho thấy các cơ sở dữ liệu này chủ yếu phản ánh nguồn gốc châu Âu, và thực tế là thiếu thông tin gây bệnh đặc thù cho các nhóm dân số lớn, đặc biệt là dữ liệu gây bệnh đặc thù cho người gốc Phi. Do đó, kết quả xét nghiệm gen cho người không phải gốc Âu có thể kém chính xác, khó khăn hơn hoặc đơn giản là không thể thực hiện.  \n\nVí dụ về da liễu:  \nNói chung, bệnh nhân có màu da sẫm thường mắc bệnh da ở giai đoạn nặng hơn và có tỷ lệ sống sót thấp hơn so với bệnh nhân da sáng. Có khả năng chỉ các nhóm da sáng mới được hưởng lợi vì thiếu sự tham gia của bệnh nhân da sẫm trong huấn luyện và phát triển mô hình. Nếu thuật toán chủ yếu dựa vào cách tổn thương da xuất hiện trên da sáng, thì về lý thuyết, tổn thương trên bệnh nhân da màu ít có khả năng được chẩn đoán và do đó ít được hưởng lợi từ giải pháp AI.  \nNhững ví dụ này cho bạn thấy mức độ phổ biến của các thách thức liên quan đến công bằng và thiên lệch trong giải pháp AI cho y tế.  \n\nCÁC LOẠI THIÊN LỆCH  \nThiên lệch có thể xảy ra ở hầu hết mọi giai đoạn xây dựng và triển khai mô hình AI - từ thu thập dữ liệu đến triển khai mô hình.  \nCác loại thiên lệch:  \n• Thiên lệch lịch sử  \n• Thiên lệch đại diện  \n• Thiên lệch đo lường  \n• Thiên lệch tổng hợp  \n• Thiên lệch đánh giá  \n• Thiên lệch triển khai  \nBản quyền 2020 © Đại học Stanford 32  \n\nThiên lệch lịch sử xảy ra nếu trạng thái hiện tại hoặc quá khứ của thế giới ảnh hưởng đến mô hình theo cách mà dự đoán của nó bị coi là không công bằng theo các giá trị và chuẩn mực xã hội. Thiên lệch lịch sử đề cập đến phán xét dựa trên định kiến hoặc thành kiến có sẵn. Thuật toán AI hoàn toàn phụ thuộc vào dữ liệu và thiên lệch lịch sử được mã hóa trong dữ liệu thực tế không thể bị khắc phục ngay cả khi lấy mẫu và chọn đặc trưng hoàn hảo. Do đó, cần nhớ rằng dữ liệu y tế lịch sử, nói chung, là rất nam giới và rất da trắng, điều này có tác động thực tế.  \n\nThiên lệch đại diện (còn gọi là thiên lệch lấy mẫu) phát sinh khi mẫu thu thập để huấn luyện giải pháp AI không đại diện cho phân bố thực tế của dân số mà nó dự định áp dụng. Nó xảy ra khi một số phần của dân số sử dụng cuối cùng bị đại diện thiếu trong dữ liệu huấn luyện.  \n\nThiên lệch đo lường phát sinh trong các tình huống nếu nhiễu không được phân phối ngẫu nhiên mà khác nhau giữa các nhóm, dẫn đến hiệu suất khác biệt. Thường thì các đặc trưng và nhãn có sẵn và đo lường được chỉ là các đại diện nhiễu của biến thực sự quan tâm. Thông thường, không thể thay đổi dữ liệu, một số thiên lệch lịch sử có thể gắn liền với dữ liệu – nhưng nhận thức về vấn đề là quan trọng và các chiến lược giảm nhẹ có thể được xác định bằng các biện pháp phòng ngừa như hành động tiền xử lý và hậu xử lý.  \n\nThiên lệch tổng hợp xảy ra khi phát triển mô hình khi chúng ta cố gắng kết hợp các nhóm dân số khác nhau có phân phối kết quả nghiên cứu khác nhau. Vấn đề này được gọi là infra-marginality và đòi hỏi các mô hình riêng biệt cho các nhóm dân số khác nhau hoặc đưa biến nhân khẩu học vào mô hình để tính đến sự khác biệt hệ thống. Về phát triển mô hình, không có mô hình nào phù hợp cho tất cả. Để xác định thiên lệch tổng hợp, nhà phát triển cần hiểu các nhóm khác biệt có ý nghĩa và lý do tại sao chúng khác nhau.  \n\nThiên lệch đánh giá xảy ra trong quá trình xác thực và tinh chỉnh mô hình. Thiên lệch đánh giá phát sinh nếu dữ liệu kiểm tra, thường bao gồm các bộ dữ liệu chuẩn bên ngoài, không đại diện cho dân số cuối cùng mà giải pháp AI sẽ được áp dụng. Đây là sự khác biệt giữa dữ liệu dùng để đánh giá mô hình và dữ liệu dùng cho dự đoán thực tế của mô hình. Vì các nhà phát triển chủ yếu sử dụng bộ dữ liệu chuẩn hoặc bộ dữ liệu tổng hợp để huấn luyện, việc đánh giá của họ thường không phù hợp với thực tế. Một giải pháp cho vấn đề này là xác thực bên ngoài mô hình AI trên dữ liệu chưa từng thấy được chọn từ dân số mục tiêu. Thiên lệch đánh giá cũng có thể phát sinh nếu sử dụng các chỉ số hiệu suất không phù hợp. Thiên lệch đánh giá cũng đề cập đến việc sử dụng chỉ số đánh giá không hiệu quả và để tránh điều này, nên sử dụng các chỉ số đánh giá chi tiết và toàn diện.  \n\nThiên lệch triển khai phát sinh trong quá trình triển khai mô hình. Nó đề cập đến việc sử dụng mô hình không phù hợp hoặc diễn giải sai kết quả của nó. Nói cách khác, nếu mục đích sử dụng mô hình khác với cách nó được sử dụng, sẽ xảy ra thiên lệch triển khai. Thiên lệch triển khai là sự tương tác của xã hội với giải pháp AI - cách xã hội hoặc cộng đồng y tế sử dụng giải pháp AI và kết quả của nó.  \nBản quyền 2020 © Đại học Stanford 33  \n\nCÔNG BẰNG THUẬT TOÁN  \nPhân tích đạo đức các giải pháp AI trong chăm sóc sức khỏe đòi hỏi chúng ta phải xem xét về công bằng, hoặc chính xác hơn là công lý, tập trung vào sức khỏe và mạng sống của con người, không chỉ là kết quả đầu ra. Nhiều y học lịch sử đã bị ảnh hưởng bởi chuẩn mực da trắng, là cơ sở của nhiều thực tế y khoa. Điều này thể hiện rõ qua việc thiếu sự tham gia của bệnh nhân đa dạng trong nghiên cứu lâm sàng.  \nCó kiến thức mà người trong ngành không có. Đưa các góc nhìn đa dạng thực sự nâng cao chất lượng và độ chính xác của nghiên cứu khoa học của bạn.  \nMột khó khăn lớn trong phát triển các thuật toán AI công bằng là không có khái niệm công bằng phổ quát. Nhiều định nghĩa khác nhau đã được các nhà nghiên cứu đề xuất qua nhiều năm và có thể được nhóm lại thành ba loại chính: chống phân loại, công bằng phân loại và hiệu chỉnh. Các định nghĩa công bằng này đều có những hạn chế thống kê đáng kể. Do đó, cần đặc biệt cẩn trọng và nhận thức về những hạn chế và điểm yếu của các khái niệm này khi áp dụng trong đánh giá mô hình.  \n\nChống phân loại hoặc “công bằng thông qua không nhận biết”  \n1. Yêu cầu loại bỏ bất kỳ thuộc tính được bảo vệ nào trong mô hình hóa kết quả  \n2. Yêu cầu loại bỏ bất kỳ đặc điểm không được bảo vệ nào là đại diện cho thuộc tính được bảo vệ  \nHạn chế chính của định nghĩa công bằng này là một số mô hình rủi ro lâm sàng cần phải bao gồm rõ ràng các thuộc tính được bảo vệ để đảm bảo công bằng. Đặc biệt, điều này áp dụng cho các tình huống mà phân phối rủi ro thực sự khác nhau giữa các nhóm phụ, được gọi là vấn đề infra-marginality. Do đó, một mô hình chính xác phải bao gồm các thuộc tính được bảo vệ, nhưng cũng phải học cách tránh thiên lệch dựa trên các thuộc tính này.  \nCác giải pháp AI sử dụng bộ dữ liệu có thể thiếu đại diện cho một số nhóm nhất định, có thể cần dữ liệu huấn luyện bổ sung để cải thiện độ chính xác trong ra quyết định và giảm kết quả không công bằng.  \nChống phân loại yêu cầu loại bỏ bất kỳ thuộc tính được bảo vệ nào trong mô hình hóa kết quả.  \n\nCông bằng phân loại yêu cầu hiệu suất dự đoán ngang nhau giữa bất kỳ nhóm được bảo vệ nào. Khi chọn các chỉ số để xem xét, điều quan trọng là phải lưu ý đến các hiểu biết có thể hành động được từ kết quả mô hình. Hai chỉ số được cộng đồng học máy đặc biệt quan tâm:  \nBản quyền 2020 © Đại học Stanford 34  \n1. Tỷ lệ dương tính giả: Xác suất dự đoán kết quả dương tính khi kết quả thực là âm tính nên giống nhau bất kể thuộc tính được bảo vệ của bệnh nhân  \n2. Tỷ lệ ...\n\n---\n\nDo văn bản rất dài, nếu bạn cần dịch tiếp phần sau hoặc muốn chỉnh sửa chi tiết hơn, vui lòng cho biết!",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\n**Các quyết định dương tính:** Xác suất dự đoán một kết quả dương tính không nên thay đổi giữa các nhóm nhân khẩu học khác nhau khi mọi yếu tố khác đều như nhau. Điều này còn được gọi là “bình đẳng nhân khẩu học” (demographic parity) vì nó yêu cầu các dự đoán của bộ phân loại phải độc lập với các thuộc tính được bảo vệ. Những định nghĩa này gặp vấn đề khi phân phối rủi ro khác nhau giữa các nhóm, một vấn đề được gọi là “infra-marginality”. “Phân loại bình đẳng” (classification parity) yêu cầu hiệu suất dự đoán ngang nhau giữa các nhóm. “Hiệu chỉnh” (calibration) là khi mô hình đạt được sự đồng thuận tốt giữa dự đoán của mô hình và kết quả thực tế. Hiệu chỉnh nghĩa là khi điều kiện hóa trên các ước lượng rủi ro, kết quả nên độc lập với các thuộc tính được bảo vệ. Hãy nghĩ về hiệu chỉnh như một phép so sánh giữa đầu ra thực tế và đầu ra kỳ vọng do hệ thống cung cấp. Tuy nhiên, hiệu chỉnh có thể bị thao túng thông qua phân phối rủi ro khác nhau giữa các nhóm. Hiệu chỉnh mô hình là một khía cạnh quan trọng trong phát triển và cần được đánh giá trước khi triển khai mô hình.\n\n**Áp dụng các thước đo công bằng:**\n- **Chống phân loại (Anti-classification):** Kiểm tra yêu cầu không sử dụng bất kỳ thuộc tính được bảo vệ nào trong quy tắc quyết định. Việc này trở nên phức tạp hơn khi cố gắng áp đặt điều kiện nghiêm ngặt hơn là không sử dụng bất kỳ đại diện (proxy) nào của các thuộc tính được bảo vệ.\n- **Phân loại bình đẳng (Classification parity):** Sau khi chọn ra 2-3 chỉ số hiệu suất liên quan nhất, chúng ta đánh giá sự khác biệt hiệu suất trên tập kiểm tra giữa các nhóm nhân khẩu học khác nhau. Luôn tốt hơn khi tính toán khoảng tin cậy thực nghiệm của thống kê này để giảm sự phụ thuộc vào tập kiểm tra.\n- **Hiệu chỉnh (Calibration):** Chỉ xem xét tỷ lệ tổng thể giữa dự đoán và kết quả quan sát được trên các nhóm nhân khẩu học.\n\n**MINH BẠCH**\nĐiều quan trọng là phải xem xét liệu dân số được ghi nhận trong hệ thống EHR có đại diện cho cộng đồng rộng lớn hơn hay không, đặc biệt nếu các dữ liệu này đến từ một trung tâm y tế học thuật. Nếu các giải pháp AI được phát triển trên các quần thể không đại diện, tính hữu ích và khả năng áp dụng của những tiến bộ này cho cộng đồng bệnh nhân rộng lớn hơn sẽ bị đặt dấu hỏi. Điều này liên quan đến một vấn đề quan trọng về minh bạch và báo cáo, và nhiều nghiên cứu AI, đặc biệt là học máy, không báo cáo sự phân bố nhân khẩu học của dữ liệu huấn luyện được sử dụng để phát triển và huấn luyện các mô hình. Việc thiếu báo cáo khiến rất khó đánh giá sự thiên lệch và công bằng của giải pháp AI cũng như khả năng áp dụng của nó trên các quần thể khác nhau. Các nghiên cứu có đề cập đến các biến số thường không báo cáo liệu chúng có được đưa vào làm đầu vào mô hình hay không. Trong các nghiên cứu báo cáo nhân khẩu học, các quần thể trung bình bao gồm tỷ lệ người da trắng và da đen cao hơn nhưng lại ít người gốc Tây Ban Nha hơn so với dân số chung. Mặc dù mỗi nghiên cứu có thể không áp dụng cho toàn bộ dân số, những phát hiện này nhấn mạnh sự thiếu minh bạch hiện tại trong việc báo cáo chi tiết dữ liệu huấn luyện được sử dụng để phát triển và đánh giá các mô hình học máy trong y tế. Để đảm bảo việc triển khai và ứng dụng không thiên lệch bất kỳ mô hình AI nào trong y tế, cần có thông tin chi tiết về dữ liệu được sử dụng để phát triển và huấn luyện mô hình. Như một giải pháp cho việc báo cáo minh bạch và xác định các thực hành tốt nhất trong thiết kế mô hình học máy để tính đến sự thiên lệch và công bằng, mẫu MINIMAR được đề xuất. (MINIMAR = Thông tin tối thiểu cho báo cáo AI y tế)\n\n**Yêu cầu của MINIMAR:**\n1. Bao gồm thông tin về quần thể cung cấp dữ liệu huấn luyện, về nguồn dữ liệu và cách chọn nhóm nghiên cứu.\n2. Bao gồm thông tin về nhân khẩu học của dữ liệu huấn luyện theo cách cho phép so sánh với quần thể mà mô hình sẽ được áp dụng.\n3. Cung cấp thông tin chi tiết về kiến trúc và phát triển mô hình để có thể diễn giải mục đích của mô hình và so sánh với các mô hình tương tự.\n4. Đánh giá, tối ưu hóa và xác thực mô hình cần được báo cáo minh bạch để làm rõ cách tối ưu hóa mô hình cục bộ có thể đạt được và cho phép tái lập cũng như chia sẻ tài nguyên.\n\nBạn có thể hiểu rằng bằng cách cung cấp các chi tiết này về dữ liệu huấn luyện và quần thể, thiết kế và mục đích mô hình, người dùng cuối sẽ có hiểu biết tốt về cách triển khai mô hình tốt nhất và ở những quần thể nào.\n\n**ĐÁNH GIÁ HẠ LƯU**\nMặc dù chúng ta đã đề cập đến nhiều chủ đề trong bài giảng này về thiên lệch và công bằng thuật toán, vẫn còn nhiều thách thức và cơ hội cho nghiên cứu AI công bằng:\n- **Định nghĩa công bằng:** Có nhiều định nghĩa về công bằng AI đã được đề xuất trong tài liệu. Gần như không thể hiểu được làm thế nào một giải pháp công bằng có thể giải quyết tất cả các thách thức. Việc xác định định nghĩa đúng hoặc tốt nhất vẫn đang được tranh luận.\n- **Từ bình đẳng đến công bằng:** Công bằng (equity) gợi ý rằng mỗi nhóm được cung cấp lượng tài nguyên cần thiết để có kết quả tương tự. Hiểu cách phát triển và triển khai một mô hình cung cấp cả bình đẳng và công bằng là một sự thay đổi mô hình trong cách nghĩ về cung cấp dịch vụ y tế và là một lĩnh vực nghiên cứu đang hoạt động.\n- **Nhận diện thiên lệch trong mô hình, đặc biệt là trong bộ dữ liệu:** Nhiều thiên lệch là có hệ thống và chúng ta thường không nhận ra sự tồn tại của chúng. Chúng ta vẫn còn một chặng đường dài trước khi có thể giảm thiểu có hệ thống các thiên lệch này và cung cấp cho các chuyên gia công cụ phù hợp để giải quyết các vấn đề này tại điểm chăm sóc.\n\nViệc thu thập và báo cáo kết quả AI, khuyến nghị lâm sàng và quyết định của bệnh nhân cùng với kết quả cuối cùng là điều cần thiết để chịu trách nhiệm với tư cách là các tổ chức y tế và bác sĩ lâm sàng. Công việc này và sự minh bạch trong báo cáo các giải pháp AI là hoàn toàn quan trọng đối với các quần thể gặp khó khăn trong việc tin tưởng vào hệ thống y tế. Điều then chốt là sử dụng AI theo cách thực sự mang lại lợi ích cho tất cả các nhóm, điều này đòi hỏi đánh giá cẩn trọng và diễn giải của con người.\n\n**TÀI LIỆU THAM KHẢO VÀ ĐỌC THÊM**\nAdamson, A. S. và A. Smith. 2018. “Machine Learning and Health Care Disparities in Dermatology.” JAMA Dermatol 154(11): 1247-48.  \nBeery, T. A. 1995. “Gender bias in the diagnosis and treatment of coronary artery disease.” Heart Lung 24(6): 427-35.  \nBozkurt, S., E. Cahan, M. G. Seneviratne, R. Sun, J. A. Lossio-Ventura, J. P. A. Ioannidis, và T. Hernandez-Boussard. 2020. “Reporting of demographic data, representativeness and transparency in machine learning models using electronic health records.”  \nCorbett-Davies, S. và Goel, S., 2018. The measure and mismeasure of fairness: A critical review of fair machine learning. arXiv preprint arXiv:1808.00023.  \nHernandez-Boussard, T., S. Bozkurt, J. P. A. Ioannidis, và N. H. Shah. 2020. “MINIMAR (MINimum Information for Medical AI Reporting): Developing reporting standards for artificial intelligence in health care.” J Am Med Inform Assoc.  \nKessler, M. D., L. Yerges-Armstrong, M. A. Taub, A. C. Shetty, K. Maloney, L. J. B. Jeng, I. Ruczinski, A. M. Levin, L. K. Williams, T. H. Beaty, R. A. Mathias, K. C. Barnes, T. D. O'Connor, và C. o. A. a. A.-a. P. i. t. A. (CAAPA). 2016. “Challenges and disparities in the application of personalized genomic medicine to populations with African ancestry.” Nat Commun 7: 12521.  \nObermeyer, Z., B. Powers, C. Vogeli, và S. Mullainathan. 2019. “Dissecting racial bias in an algorithm used to manage the health of populations.” Science 366(6464): 447-53.  \nParthipan, A., I. Banerjee, K. Humphreys, S. M. Asch, C. Curtin, I. Carroll, và T. Hernandez-Boussard. 2019. “Predicting inadequate postoperative pain management in depressed patients: A machine learning approach.” PLoS One 14(2): e0210575.  \nSpanakis, E. K. và S. H. Golden. 2013. “Race/ethnic difference in diabetes and diabetic complications.” Curr Diab Rep 13(6): 814-23.  \nSuresh, H. và J. V. Guttag. 2019. “A framework for understanding unintended consequences of machine learning.” arXiv preprint arXiv:1901.10002.\n\n---\n\nIf you need the next section (MODULE 5: THE REGULATORY ENVIRONMENT FOR AI IN HEALTHCARE) translated, please let me know!",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\n**An toàn lâm sàng, hiệu quả và hiệu suất. Quy trình Đánh giá Lâm sàng bao gồm ba thành phần.**\n\n**Liên kết Lâm sàng Hợp lệ (Loại I):** Liệu có một liên kết lâm sàng hợp lệ giữa đầu ra của SaMD của bạn và tình trạng lâm sàng mục tiêu của SaMD không? Tính hợp lệ khoa học của giải pháp AI hoặc mức độ mà đầu ra của SaMD được chấp nhận lâm sàng hoặc có cơ sở vững chắc (dựa trên bằng chứng khoa học đã được thiết lập), và phản ánh chính xác tình huống và tình trạng chăm sóc sức khỏe được xác định trong môi trường thực tế. Đây là chỉ số về mức độ chấp nhận lâm sàng và sự tin tưởng vào đầu ra của SaMD. Bằng chứng tối thiểu để hỗ trợ liên kết lâm sàng có thể bao gồm:\n• Tìm kiếm tài liệu\n• Nghiên cứu lâm sàng gốc\n• Hướng dẫn của các hội chuyên môn\n• Ví dụ về cách mô hình của bạn có thể tạo ra bằng chứng mới\n• Phân tích dữ liệu thứ cấp\n• Hiệu suất của một thử nghiệm lâm sàng dựa trên giải pháp AI của bạn\n• Yêu cầu đối với quy định AI và đảm bảo sự chấp nhận lâm sàng cũng như việc ứng dụng giải pháp AI trong môi trường chăm sóc sức khỏe\n\n**Liên kết mới** – các liên kết được AI của bạn phát hiện lần đầu:\n• Vì tài liệu và các thử nghiệm lâm sàng ngẫu nhiên hiện có không tồn tại cho liên kết này, có các giải pháp khác để điều chỉnh phần mềm này, có thể bao gồm thực hiện thử nghiệm lâm sàng hoặc phân tích dữ liệu thứ cấp.\n\n**Xác thực Phân tích (Loại II):** Đánh giá liệu giải pháp AI của bạn có xử lý đúng dữ liệu đầu vào để tạo ra dữ liệu đầu ra chính xác, đáng tin cậy và chính xác hay không. Là một phần của giai đoạn xác minh và xác thực mà nhà sản xuất AI nên thực hiện. Cung cấp bằng chứng khách quan rằng giải pháp AI đã được xây dựng đúng cách và việc xử lý dữ liệu là đáng tin cậy. Có thể đến từ thực hành kỹ thuật phần mềm tốt hoặc từ việc tạo ra bằng chứng mới thông qua việc sử dụng cơ sở dữ liệu đã được chọn lọc hoặc dữ liệu bệnh nhân đã thu thập trước đó.\n\n**Xác thực Lâm sàng (Loại III):** Việc sử dụng dữ liệu đầu ra của AI của bạn có đạt được mục đích dự định trong dân số mục tiêu trong bối cảnh chăm sóc lâm sàng không? Liên quan đến tác động tích cực của giải pháp AI đối với sức khỏe của cá nhân hoặc cộng đồng. Xác thực lâm sàng nên:\n• Kết quả lâm sàng có thể đo lường, liên quan đến bệnh nhân\n• Bao gồm kết quả liên quan đến chức năng của mô hình\n• Tác động tích cực đến sức khỏe cá nhân hoặc cộng đồng\n\n**Trước khi ra mắt sản phẩm AI (trước thị trường), phải có bằng chứng về:**\n• Độ chính xác của AI\n• Độ đặc hiệu\n• Độ nhạy\n• Độ tin cậy\n• Tính khả dụng\n• Hạn chế\n• Phạm vi sử dụng trong môi trường sử dụng dự kiến với người dùng dự kiến\n\n**Sau khi ra mắt sản phẩm (sau thị trường), sản phẩm phải:**\n• Tiếp tục thu thập dữ liệu hiệu suất thực tế để\n• Hiểu rõ hơn nhu cầu chăm sóc sức khỏe nhằm đảm bảo giải pháp AI đáp ứng các nhu cầu đó\n• Giám sát liên tục an toàn, hiệu quả và hiệu suất của sản phẩm trong sử dụng thực tế\n\nIMDRF xác định rằng xác thực lâm sàng là một thành phần cần thiết của quy định và có thể được chứng minh thông qua nhiều con đường, bao gồm:\n• Tham khảo dữ liệu hiện có từ các nghiên cứu được thực hiện cho cùng mục đích sử dụng\n• Tham khảo dữ liệu hiện có từ các nghiên cứu cho mục đích sử dụng khác, nếu có thể biện minh cho việc ngoại suy dữ liệu đó\n• Tạo ra dữ liệu lâm sàng mới cho mục đích sử dụng cụ thể\n\n**Quy trình Đánh giá Lâm sàng là một thành phần quan trọng của môi trường pháp lý.**\n\n---\n\n**ỨNG DỤNG FDA**\n\nNgoài quy trình kiểm soát chung, còn có các yêu cầu kiểm soát quy định khác (yêu cầu về dữ liệu) đi kèm với một đơn đăng ký SaMD tùy thuộc vào phân loại rủi ro của ứng dụng (1 - 4), có thể bao gồm một trong các thành phần quy định sau:\n• Thông báo trước thị trường 510(k)\n• Thông báo De Novo\n• Phê duyệt trước thị trường (PMA)\n\n**Thông báo trước thị trường 510(k)** là yêu cầu dữ liệu đơn giản nhất, nếu SaMD tương tự với một sản phẩm đã có trên thị trường. Mục đích là thông báo cho cơ quan quản lý rằng giải pháp AI là an toàn và hiệu quả, được xác định bằng cách chứng minh giải pháp AI tương đương với một thiết bị đã được lưu hành hợp pháp, thường được gọi là “predicate”. Để xác định sự tương đương, giải pháp AI phải có:\n• Cùng mục đích sử dụng với predicate VÀ có cùng đặc điểm công nghệ, HOẶC\n• Cùng mục đích sử dụng với predicate và công nghệ khác nhưng không làm phát sinh câu hỏi về an toàn hoặc hiệu quả VÀ giải pháp AI ít nhất an toàn và hiệu quả như predicate\n\nKhi ngày càng nhiều ứng dụng được phê duyệt, thông báo trước thị trường sẽ trở thành con đường dễ dàng và hiệu quả hơn cho việc điều chỉnh.\n\n**Thông báo De Novo:** Được nộp khi không có “predicate”. Giới hạn cho SaMD Loại I và Loại II và là một quy trình phân loại dựa trên rủi ro. Thông báo De Novo nên bao gồm:\n• Dữ liệu lâm sàng (nếu có) liên quan để hỗ trợ đảm bảo an toàn và hiệu quả của giải pháp AI\n• Dữ liệu phi lâm sàng bao gồm kiểm tra hiệu suất tại bàn thử nghiệm\n• Mô tả về lợi ích có thể có của giải pháp AI so với các rủi ro có thể xảy ra hoặc dự đoán khi sử dụng đúng mục đích\n\n**Phê duyệt trước thị trường (PMA):** Yêu cầu đối với SaMD có rủi ro cao (Loại III và IV). Là ứng dụng được quản lý nghiêm ngặt nhất bởi FDA. Bao gồm các nghiên cứu kỹ thuật nghiêm ngặt, nghiên cứu phòng thí nghiệm phi lâm sàng, nghiên cứu phòng thí nghiệm và điều tra lâm sàng. Trước khi được phê duyệt PMA, người nộp đơn phải cung cấp bằng chứng khoa học hợp lệ chứng minh sự đảm bảo hợp lý về an toàn và hiệu quả cho mục đích sử dụng của thiết bị.\n\n**Sau khi giải pháp AI nhận được phê duyệt quản lý, có thể cần sửa đổi trong một số trường hợp.** Yêu cầu gửi yêu cầu sửa đổi nếu có rủi ro mới hoặc thay đổi rủi ro hiện có. Có thể cần sửa đổi nếu có:\n• Thay đổi kiểm soát rủi ro để ngăn ngừa tổn hại nghiêm trọng\n• Thay đổi ảnh hưởng đáng kể đến chức năng lâm sàng hoặc hiệu suất. Thay đổi chức năng lâm sàng có thể bao gồm\n  o Chỉ định sử dụng mới\n  o Hiệu quả lâm sàng mới\n  o Thay đổi công nghệ đáng kể ảnh hưởng đến đặc điểm hiệu suất\n\nCác sửa đổi SaMD thường thuộc ba loại:\n1. Thay đổi hiệu suất\n   o Ví dụ: Bổ sung dữ liệu huấn luyện mới hoặc thay đổi kiến trúc AI có thể làm thay đổi hiệu suất\n2. Thay đổi đầu vào mô hình\n   o Ví dụ: Bổ sung các nguồn khác nhau của cùng một đầu vào hoặc thêm đầu vào mới chưa từng được xem xét trước đó\n3. Thay đổi mục đích sử dụng của đầu ra\n   o Ví dụ: Thay đổi bệnh (áp dụng cho tình trạng mới)\n\nSửa đổi phần mềm là phổ biến và thiết yếu trong toàn bộ vòng đời của giải pháp AI.\n\n---\n\n**PHÊ DUYỆT SẢN PHẨM**\n\nTheo khung do IMDRF đề xuất, FDA đã phát triển sơ đồ liên quan đến vòng đời sản phẩm tổng thể (TPLC) cho quy trình AI.\n\nCó 4 thành phần riêng biệt trong vòng đời sản phẩm tổng thể:\n1. Văn hóa chất lượng và xuất sắc tổ chức, còn gọi là Thực hành Máy học Tốt (Good Machine Learning Practices). Bao gồm tất cả các thành phần cần xem xét khi phát triển giải pháp AI, như:\n   o Lựa chọn và quản lý dữ liệu\n   o Huấn luyện và điều chỉnh mô hình\n   o Xác thực mô hình\n2. Đảm bảo trước thị trường về an toàn và hiệu quả của giải pháp AI. Dự kiến an toàn và hiệu quả được giám sát liên tục trong suốt vòng đời, bao gồm rủi ro và an toàn bệnh nhân. Cơ quan quản lý mong đợi nhà sản xuất thực hiện đánh giá rủi ro và đảm bảo các rủi ro được giảm thiểu hợp lý trong suốt TPLC.\n3. Giám sát thường xuyên an toàn và mục đích sử dụng, được sử dụng để xác định khi nào cần sửa đổi phần mềm. Việc giám sát thường xuyên mô hình đã triển khai là cần thiết và nên bao gồm khả năng ghi lại và theo dõi hiệu suất mô hình.\n4. Học liên tục được kỳ vọng từ SaDM sử dụng Dữ liệu Thực tế. “Học liên tục” không phải là “máy học”. Nó đề cập đến việc thu thập thông tin sau thị trường để cập nhật và đánh giá giải pháp AI hiện tại của bạn. Sơ đồ TPLC cho thấy cách các cơ quan quản lý nghĩ về việc sử dụng dữ liệu thực tế cho học liên tục, nền tảng của hệ thống chăm sóc sức khỏe học tập.\n\n**Thuật toán khóa** là các giải pháp AI cung cấp cùng một kết quả mỗi khi cùng một đầu vào được cung cấp. Thường là các chức năng cố định cho một tập hợp đầu vào nhất định và có thể sử dụng quy trình thủ công để cập nhật và xác thực.\n\n**Làm thế nào để điều chỉnh các giải pháp AI “thích nghi” hoặc ứng dụng máy học?**\n• Sau khi triển khai, các loại mô hình thích nghi này có thể cung cấp đầu ra khác so với đầu ra đã được phê duyệt ban đầu cho một tập hợp đầu vào nhất định. Những thay đổi tự động này sử dụng một quy trình xác định rõ, nhằm cải thiện kết quả dựa trên dữ liệu mới hoặc bổ sung được đưa vào làm đầu vào.\n\nCó hai giai đoạn cho thuật toán thích nghi:\no Giai đoạn học: Thuật toán “học” cách thay đổi hành vi, dựa trên việc bổ sung các loại đầu vào mới hoặc các trường hợp mới vào tập huấn luyện hiện có\no Giai đoạn cập nhật: Thuật toán sẽ cập nhật khi phiên bản mới của thuật toán được triển khai\n\nĐây là một sự thay đổi mô hình trong quy trình quản lý và đòi hỏi một vòng đời sản phẩm mới cho phép các thiết bị này liên tục cải tiến trong khi vẫn đảm bảo các biện pháp bảo vệ hiệu quả.\n\n**Các lưu ý cho môi trường quản lý đối với một mô hình AI:**\n1. Nhà phát triển nên nhận thức về Phân loại Rủi ro SaMD, vòng đời sản phẩm tổng thể (TPLC) và Thực hành Máy học Tốt (GMLP)\n2. Dân số, hiệu suất và mục đích sử dụng là các khía cạnh của mô hình có thể được điều chỉnh và bất kỳ thay đổi nào đối với các đặc điểm này sau khi phê duyệt sẽ yêu cầu thông báo sửa đổi\n3. Mục đích sử dụng và tình trạng chăm sóc sức khỏe của mô hình AI quyết định mức độ quản lý và phân loại rủi ro\n4. An toàn và hiệu quả phải được giám sát liên tục sau thị trường bằng dữ liệu thực tế để đảm bảo hệ thống chăm sóc sức khỏe học tập\n\n---\n\n**Ví dụ – Arterys**\n• Chỉ định sử dụng: Arterys là phần mềm sử dụng hình ảnh tim mạch thu được từ máy cộng hưởng từ (MR). Nó phân tích dòng máu từ tim bằng hình ảnh MR. Đầu ra nhằm hỗ trợ các bác sĩ tim mạch, bác sĩ X-quang và các chuyên gia chăm sóc sức khỏe khác trong quyết định lâm sàng.\n• Phân loại rủi ro: Loại II\n  o Ý nghĩa thông tin là “thông báo quản lý lâm sàng”\n  o Tình trạng chăm sóc sức khỏe là “nghiêm trọng”\n\n**Ví dụ – IDx-DR**\n• Chỉ định sử dụng: IDx-DR là thiết bị phần mềm chẩn đoán võng mạc tích hợp thuật toán thích nghi để đánh giá hình ảnh nhãn khoa nhằm sàng lọc chẩn đoán phát hiện các bệnh hoặc tình trạng võng mạc\n• Phân loại rủi ro: Loại II\n  o Ý nghĩa thông tin là “điều khiển quản lý lâm sàng”\n  o Tình trạng chăm sóc sức khỏe là “nghiêm trọng”\n\n**Ví dụ – Guardian Connect (Medtronic)**\n• Chỉ định sử dụng: Hệ thống Guardian Connect được chỉ định để theo dõi liên tục hoặc định kỳ mức đường huyết trong dịch dưới da, ở bệnh nhân (14 đến 75 tuổi) được chẩn đoán mắc bệnh tiểu đường.\n• Phân loại rủi ro: Loại II\n  o Ý nghĩa thông tin là “điều khiển quản lý lâm sàng”\n  o Tình trạng chăm sóc sức khỏe là “nghiêm trọng”\n\nFDA không điều chỉnh một số loại công cụ hỗ trợ quyết định lâm sàng (CDS) theo đạo luật 21st century cures. Ba tiêu chí xác định liệu CDS có được điều chỉnh như một SaMD hay không:\n1. Phần mềm không được nhận, phân tích hoặc xử lý hình ảnh y tế hoặc tín hiệu từ thiết bị chẩn đoán in vitro hoặc từ bất kỳ hệ thống thu nhận tín hiệu nào khác\n2. Chuyên gia chăm sóc sức khỏe phải có khả năng hiểu cơ sở của các khuyến nghị của phần mềm\n3. Phần mềm không được dùng làm nguồn duy nhất cho các khuyến nghị về điều trị, chẩn đoán hoặc phòng ngừa bệnh\n\nFDA không điều chỉnh các giải pháp AI là “xét nghiệm phát triển trong phòng thí nghiệm” được thiết kế, phát triển và triển khai trong một môi trường chăm sóc sức khỏe duy nhất.\n\n**Chương trình Tiền chứng nhận Phần mềm Sức khỏe Kỹ thuật số của FDA (Pre-Cert):**\n• Đơn giản hóa việc điều chỉnh các giải pháp AI\n• Các tổ chức có thể trở thành “được phê duyệt” cho phép họ đưa sản phẩm ra thị trường mà không cần đánh giá trước thị trường, với điều kiện sản phẩm là “rủi ro thấp”\n• Sau khi được chứng nhận, tổ chức có thể thực hiện một số thay đổi nhỏ đối với sản phẩm AI mà không cần gửi yêu cầu sửa đổi\n\nMột tổ chức phải chứng minh năm nguyên tắc chất lượng và xuất sắc tổ chức của FDA để được xem xét cho chương trình Pre-Cert:\n1. Chất lượng sản phẩm\n2. An toàn bệnh nhân\n3. Trách nhiệm lâm sàng\n4. Trách nhiệm an ninh mạng\n5. Văn hóa chủ động\n\n---\n\n**MÔI TRƯỜNG TOÀN CẦU**\n\nCần lưu ý rằng có một số khác biệt trên toàn cầu về hướng dẫn quy định cho AI trong chăm sóc sức khỏe.\n\n**Quy định Bảo vệ Dữ liệu Chung (GDPR) của EU**\n• Đề ra một bộ quy định toàn diện về việc thu thập, lưu trữ và sử dụng thông tin cá nhân có thể được sử dụng trong AI\n\n---\n\n*Lưu ý: Do độ dài văn bản, bản dịch này chỉ bao gồm phần bạn đã cung cấp cho tới đoạn cuối cùng. Nếu bạn cần dịch tiếp phần còn lại hoặc điều chỉnh bản dịch, vui lòng cho biết!*",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\n**giải pháp • Mô tả quyền của công dân được nhận giải thích về các quyết định dựa trên thuật toán. Hệ quả là sẽ loại trừ việc sử dụng nhiều loại thuật toán hiện nay trong quảng cáo và mạng xã hội – và cuối cùng là trong chăm sóc sức khỏe. Bản quyền 2020 © Đại học Stanford 50 • Cung cấp sự bảo vệ dữ liệu cho công dân EU nhưng với đà phát triển AI toàn cầu, các luật này có thể ảnh hưởng đến các công ty từ Mỹ và trên toàn thế giới • Một thành phần quan trọng của quy định này là Điều 22: “Quyết định cá nhân tự động, bao gồm cả phân loại hồ sơ.” Điều 22 yêu cầu phải có sự đồng ý rõ ràng và được thông báo trước khi thu thập bất kỳ dữ liệu cá nhân nào. • “Quyền được giải thích” o Yêu cầu cung cấp thông tin có ý nghĩa về logic của AI cũng như ý nghĩa tiềm năng và hậu quả của hệ thống dựa trên dữ liệu khi có yêu cầu o Đề cập đến việc sử dụng các thuật toán hộp đen o Có thể giới hạn các loại mô hình mà nhà sản xuất có thể sử dụng trong các ứng dụng liên quan đến sức khỏe o Khiến các nhà sản xuất công nghệ dựa trên AI phải chịu trách nhiệm nhiều hơn Dù có một số khác biệt giữa các quy định của Mỹ và EU, chủ đề chung của cả hai là bảo vệ cá nhân, dữ liệu của họ và quyền được thông tin. Trung Quốc dẫn đầu về số lượng bằng sáng chế AI nhờ môi trường thuận lợi này. Quản trị AI ở Trung Quốc hướng đến phát triển “AI có trách nhiệm” và tập trung vào lợi ích xã hội thay vì lợi ích cá nhân. Trung Quốc cũng chú trọng vào việc điều chỉnh giáo dục để quốc gia này sản xuất ra nhiều lao động STEM hơn. Trung Quốc yêu cầu doanh nghiệp và công dân tư nhân phải chia sẻ dữ liệu với chính phủ – gần như ngược lại với các quy định của Mỹ và EU. Các ưu đãi cho việc chia sẻ dữ liệu và loại bỏ các kho dữ liệu biệt lập có thể đưa Trung Quốc vươn lên trong các công nghệ AI có ý nghĩa lâm sàng. Nguyên tắc quản trị AI do Bộ Khoa học và Công nghệ Trung Quốc (MOST) công bố bao gồm: 1. Hài hòa và thân thiện 2. Công bằng và công lý 3. Bao trùm và chia sẻ 4. Tôn trọng quyền riêng tư 5. An toàn/bảo mật và kiểm soát được 6. Trách nhiệm chia sẻ 7. Hợp tác mở 8. Quản trị linh hoạt Bản quyền 2020 © Đại học Stanford 51 Trung Quốc đang phát triển nhanh chóng các giải pháp AI quan trọng trong chăm sóc sức khỏe và các chính sách quản trị này rất cần thiết để cân bằng giữa đổi mới công nghệ và an toàn trong cung cấp dịch vụ y tế. Văn phòng Quản lý và Ngân sách Nhà Trắng (OMB) cung cấp Hướng dẫn về Quy định các Ứng dụng AI. Các quy định này không chỉ dành riêng cho lĩnh vực chăm sóc sức khỏe, mà còn tạo thành khung pháp lý chung cho các giải pháp AI. Mười nguyên tắc chỉ đạo này phù hợp với quy trình quản lý của FDA: 1. Phải có sự tin tưởng của công chúng vào AI o Sự tin tưởng và xác nhận của công chúng là rất quan trọng đối với việc áp dụng và chấp nhận các công nghệ này trong lĩnh vực chăm sóc sức khỏe o Quyền riêng tư và các rủi ro khác phải được giải quyết với các chiến lược giảm thiểu phù hợp, được ghi chép đầy đủ và báo cáo minh bạch 2. Phải có sự tham gia của công chúng vào phát triển AI o Cần có nhiều cơ hội để công chúng cung cấp thông tin và tham gia ở tất cả các giai đoạn có thể của quá trình “ban hành quy tắc” 3. Các giải pháp AI phải dựa trên tính toàn vẹn khoa học - xác thực lâm sàng trong quy trình đánh giá lâm sàng do IMDRF đề xuất o AI trong chăm sóc sức khỏe nên dựa trên thông tin và quy trình khoa học, kỹ thuật có khả năng ảnh hưởng rõ rệt và đáng kể đến chính sách công hoặc quyết định của khu vực tư nhân – và các tiêu chuẩn này phải được giữ ở mức chất lượng, minh bạch và tuân thủ cao nhất o Thực tiễn tốt nhất bao gồm nêu rõ điểm mạnh, điểm yếu, tối ưu hóa hoặc kết quả dự kiến, giảm thiểu thiên vị và các mục đích sử dụng phù hợp với kết quả ứng dụng AI o Dữ liệu dùng để huấn luyện hệ thống AI phải có chất lượng đủ tốt cho mục đích sử dụng dự kiến 4. Mỗi giải pháp AI phải có thành phần Đánh giá và Quản lý Rủi ro o Cần áp dụng phương pháp dựa trên rủi ro để xác định rủi ro nào chấp nhận được và rủi ro nào có khả năng gây hại không chấp nhận được, hoặc có chi phí dự kiến lớn hơn lợi ích dự kiến o Nếu một công cụ AI thất bại, mức độ và bản chất của hậu quả sẽ xác định mức độ và loại nỗ lực quản lý phù hợp để nhận diện và giảm thiểu rủi ro 5. Lợi ích và Chi phí o Để một thuật toán AI được triển khai, nó phải mang lại lợi ích tiềm năng đáng kể Bản quyền 2020 © Đại học Stanford 52 o Trước khi triển khai giải pháp AI, các cơ quan phải xem xét đầy đủ chi phí, lợi ích và tác động xã hội liên quan đến phát triển và triển khai các ứng dụng này 6. Các giải pháp AI phải linh hoạt o Các phương pháp dựa trên hiệu suất và linh hoạt nên dễ dàng thích ứng và cập nhật – bao gồm cả việc giám sát liên tục bằng bằng chứng thực tế để cải thiện giải pháp AI 7. Các giải pháp AI phải công bằng và không phân biệt đối xử o Minh bạch về các thiên vị tiềm ẩn và khía cạnh phân biệt đối xử của thuật toán ngày càng trở nên quan trọng khi chúng ta thấy các tác hại tiềm ẩn do thiên vị được thúc đẩy hoặc làm trầm trọng thêm bởi AI 8. Các giải pháp AI cung cấp Công khai và Minh bạch sẽ thúc đẩy sự tin tưởng của công chúng o Các hệ thống y tế nên công khai khi nào giải pháp AI được sử dụng và các ứng dụng này có thể ảnh hưởng đến bệnh nhân và quyết định ra sao 9. Tất cả giải pháp AI phải giải quyết các vấn đề về An toàn và Bảo mật o An toàn và bảo mật cần được xem xét trong suốt quá trình thiết kế, phát triển, triển khai và vận hành o Cần có các kiểm soát để đảm bảo tính bảo mật, toàn vẹn và khả năng sẵn sàng của thông tin được xử lý, lưu trữ và truyền bởi hệ thống AI 10. Các giải pháp AI phải có sự tham gia của các bên liên quan đa ngành hoặc phối hợp liên cơ quan o Tất cả các lĩnh vực bị ảnh hưởng bởi giải pháp AI nên phối hợp và chia sẻ kinh nghiệm, thách thức về các giải pháp AI An toàn, minh bạch và đa ngành là những thành phần then chốt để có một giải pháp AI thành công và được cân nhắc kỹ lưỡng. TÀI LIỆU THAM KHẢO VÀ ĐỌC THÊM FDA, U. 2019. “Khung pháp lý đề xuất cho việc sửa đổi phần mềm dựa trên trí tuệ nhân tạo/học máy (AI/ML) như một thiết bị y tế (SaMD).” FDA. Bộ Y tế và Dịch vụ Nhân sinh Hoa Kỳ. Phần mềm như một thiết bị y tế (SAMD): Đánh giá lâm sàng. Hướng dẫn cho ngành công nghiệp và nhân viên FDA. 2017. Bản quyền 2020 © Đại học Stanford 53 THỰC HÀNH ĐẠO ĐỨC TỐT NHẤT THỰC HÀNH ĐẠO ĐỨC TỐT NHẤT – XÁC ĐỊNH VẤN ĐỀ Ở phần này, chúng ta sẽ tìm hiểu về các hành động cụ thể được khuyến nghị là thực hành đạo đức tốt nhất trong phát triển và triển khai AI dựa trên học máy trong các ứng dụng chăm sóc sức khỏe. Suy nghĩ về thực hành đạo đức tốt nhất sẽ bắt đầu từ giai đoạn xác định vấn đề và xác định mục đích của hệ thống AI mà bạn muốn phát triển. Đầu tiên, mục đích đó có đạo đức không, có nhằm nâng cao sức khỏe và phúc lợi của bệnh nhân không? Ngay cả khi mục đích dự định có vẻ đạo đức, liệu có thể có hậu quả tiêu cực nếu bị lạm dụng không? Ngày càng nhiều nhà khoa học dữ liệu đặt câu hỏi về mục đích và cách sử dụng các sản phẩm mà họ phát triển, dù đó là nhắm mục tiêu quảng cáo đến cá nhân qua mạng xã hội, hay nhận diện cá nhân qua thuật toán nhận diện khuôn mặt. Ví dụ, Hiệp hội Máy tính (Association of Computing Machinery), một trong những tổ chức chuyên môn hàng đầu của các nhà khoa học máy tính, đã kêu gọi tạm dừng sử dụng công nghệ nhận diện khuôn mặt vì khả năng gây tác động thành kiến đến quyền con người và pháp lý. Hiệp hội cũng khẳng định rằng các nhà phát triển, vận hành cũng như người dùng công nghệ nhận diện khuôn mặt phải chịu trách nhiệm về việc sử dụng và lạm dụng các hệ thống này. Dù những câu hỏi này có vẻ không cần thiết trong bối cảnh AI y tế vì câu trả lời đã rõ ràng, nhưng chúng đặc biệt quan trọng đối với AI được phát triển bởi các nhóm có lợi ích xung đột hoặc cạnh tranh. Môi trường chăm sóc sức khỏe đầy rẫy các lợi ích cạnh tranh vì họ hoạt động dưới các ràng buộc về nguồn lực, bao gồm tài chính, nhân sự, thiết bị và vật tư, chưa kể các động lực tài chính để cải thiện chất lượng chăm sóc. Tất cả những lợi ích và động lực này tạo áp lực để tránh một số loại bệnh nhân hoặc tránh cung cấp một số loại điều trị nhất định. Các nhà phát triển AI phải cảnh giác trong việc giảm thiểu xung đột lợi ích. Nhưng làm thế nào? Chúng ta sẽ nói cụ thể hơn về điều này, nhưng trước tiên, hãy xem xét vấn đề xác định vấn đề. Xác định vấn đề AI liên quan đến việc chuyển đổi mục tiêu cấp cao như “cải thiện chăm sóc bệnh nhân” thành các câu hỏi có thể hành động được và có thể trả lời bằng dữ liệu sẵn có. Thách thức là các câu hỏi có thể hành động và dữ liệu sẵn có thường bị giới hạn, nên nhiều điều có thể bị bỏ sót trong quá trình chuyển đổi, và các ràng buộc thực tế khi xác định vấn đề có thể dẫn đến lỗi và thiên vị không được phát hiện. Một nhiệm vụ khá phổ biến và tưởng chừng đơn giản như phân tầng rủi ro thường gặp nhiều khó khăn vì rủi ro có thể được định nghĩa theo nhiều cách khác nhau, và thường không được đo trực tiếp mà qua các biến đại diện. Chúng ta đã thấy việc sử dụng chi phí chăm sóc sức khỏe như một biến đại diện cho rủi ro hoặc nhu cầu chăm sóc sức khỏe đã dẫn đến thiên vị chủng tộc vì điểm rủi ro tạo ra từ mô hình dự đoán dựa trên chi phí đã đánh giá thấp nhu cầu chăm sóc sức khỏe của người da đen so với người da trắng có cùng điểm rủi ro. May mắn thay, thiên vị như vậy có thể được kiểm tra, ít nhất là đối với các biến mà bạn nghi ngờ có thiên vị tiềm ẩn như chủng tộc hoặc giới tính. Trong ví dụ này, bạn sẽ xem xét liệu mối quan hệ giữa điểm rủi ro do mô hình tạo ra và biến quan tâm, nhu cầu sức khỏe, có khác nhau theo chủng tộc hay không. Tương tự, phân tầng rủi ro dựa trên chi phí như một biến đại diện cho nhu cầu sức khỏe thường thiên về người lớn tuổi có bệnh mạn tính phức tạp ở cuối đời, khi chi phí chăm sóc sức khỏe phát sinh nhiều nhất, và chống lại trẻ em bị bệnh cấp tính, có thể gây tử vong nhưng có thể điều trị được. Nếu câu hỏi cần trả lời là “ai cần được chăm sóc nhiều nhất” thì cần nhớ rằng câu hỏi này không chỉ là định lượng mà còn là câu hỏi về giá trị đòi hỏi sự tinh tế. “Chăm sóc” được định nghĩa như thế nào? Câu hỏi có phân biệt giữa chăm sóc cấp tính và mạn tính không? “Nhu cầu” được định nghĩa ra sao? Nếu bệnh nhân có tình trạng không thể điều trị và do đó thường không nhận được chăm sóc tốn kém, liệu điều đó có nghĩa là mô hình nên gán cho họ điểm rủi ro thấp, hay rằng họ không cần chăm sóc? Các câu hỏi cần đặt ra khi xác định vấn đề • Mục đích của hệ thống AI có nhằm nâng cao sức khỏe và phúc lợi của bệnh nhân không? • Liệu có thể có hậu quả ngoài ý muốn nếu bị lạm dụng không? • Ý định của hệ thống là gì – nhận diện, phân loại, dự đoán? • Cái gì đang được nhận diện, phân loại hoặc dự đoán? o Ví dụ: rủi ro, bệnh, tiên lượng, chi phí, sử dụng dịch vụ y tế, nhập viện hoặc tái nhập viện, hiệu quả điều trị, suy giảm • Các thuật ngữ này được định nghĩa như thế nào? Liên quan chặt chẽ đến xác định vấn đề là lựa chọn dữ liệu. Tất nhiên, dữ liệu đã có sẵn là dễ sử dụng nhất. Nhưng điều đó không có nghĩa là đó là dữ liệu phù hợp. Ví dụ, hồ sơ sức khỏe điện tử có thể rất nhiều nhưng thiếu nhiều thông tin quan trọng cho mô hình dự đoán, như phơi nhiễm môi trường, chế độ ăn uống hoặc các yếu tố kinh tế xã hội, tất cả đều có ảnh hưởng lớn đến sức khỏe và bệnh tật. Hồ sơ sức khỏe điện tử từ một bệnh viện hoặc hệ thống y tế, hoặc dữ liệu khiếu nại bảo hiểm cũng thường không cung cấp dòng thời gian dữ liệu dọc cho một bệnh nhân theo thời gian vì bệnh nhân thường chuyển đổi giữa các nhà cung cấp dịch vụ và bảo hiểm. Và dựa vào dữ liệu từ một thời điểm duy nhất có thể gây hiểu lầm. Ngược lại, gộp dữ liệu lại có thể che lấp các mô hình quan trọng. Trong ví dụ về phân tầng rủi ro, một mô hình được huấn luyện trên dữ liệu từ nhiều nhóm tuổi có thể che lấp các mô hình trong dữ liệu của một nhóm phụ, như người trẻ tuổi. Tất nhiên, kiến thức chi tiết về sự khác biệt giữa các nhóm phụ là cần thiết để biết liệu có cần các mô hình tùy chỉnh hay không. Làm sao biết trước điều này? Bản quyền 2020 © Đại học Stanford 55 Các câu hỏi về dữ liệu • Các biến trong mô hình được dữ liệu sẵn có đại diện tốt đến mức nào? • Có sử dụng các biến đại diện không? • Có biến quan trọng nào có khả năng liên quan đến các kết quả chính mà không được đại diện trong dữ liệu sẵn có không? • Có khả năng có sự khác biệt giữa các nhóm phụ về kết quả chính, đặc biệt là theo các đặc điểm được pháp luật bảo vệ như tuổi, chủng tộc, dân tộc hoặc giới tính, hoặc các đặc điểm xã hội quan trọng như thu nhập và giáo dục không? Thực hành tốt nhất chỉ ra sự cần thiết phải bao gồm các bác sĩ lâm sàng đang hành nghề, những người hiểu rõ về nhóm bệnh nhân liên quan và các tình trạng bệnh, cũng như dữ liệu cần thiết cho mô hình. Họ cần biết điều gì...\n\n---\n\n**Lưu ý:** Do độ dài văn bản, bản dịch này dừng lại ở phần cuối cùng bạn gửi. Nếu bạn cần dịch tiếp phần còn lại hoặc cần điều chỉnh, vui lòng cho biết!",
  "Here is the Vietnamese translation of your provided English text:\n\n---\n\nDữ liệu thực sự có sẵn, và những hạn chế của dữ liệu, đặc biệt là về các thiên lệch có thể có. Điều quan trọng là phải có các thành viên trong nhóm hiểu về nguồn gốc của sai số hệ thống, chẳng hạn như liệu sai số có phát sinh do thiếu dữ liệu từ các phân nhóm dân số cụ thể, thiên lệch của bác sĩ (ví dụ như khả năng phụ nữ mắc bệnh tim được chẩn đoán thấp hơn so với nam giới), hoặc các bất bình đẳng xã hội rộng lớn hơn như sự khác biệt trong khả năng tiếp cận chăm sóc. Đó là bởi vì hiểu được nguồn gốc của sai số hệ thống sẽ chỉ ra liệu và làm thế nào các mô hình có thể tính đến thiên lệch. Các thành viên nhóm là bác sĩ lâm sàng có thể đóng vai trò then chốt ở giai đoạn xác định vấn đề, bởi vì kiến thức lâm sàng sâu rộng rất quan trọng để hiểu được các hệ quả của việc đặt câu hỏi theo một cách cụ thể.\n\nTHỰC HÀNH ĐẠO ĐỨC TỐT NHẤT – XÁC ĐỊNH XUNG ĐỘT LỢI ÍCH\n\nTrong phần này, tôi muốn nói về các thực hành đạo đức tốt nhất nhằm giải quyết vấn đề xung đột lợi ích. Trong y học và nghiên cứu y sinh, chúng ta thường xuyên đối mặt với xung đột lợi ích và đã phát triển các cách để giảm thiểu tác động tiêu cực của chúng. Vậy, điều đó được thực hiện như thế nào, và làm sao chúng ta có thể áp dụng các chiến lược đó vào việc phát triển và triển khai AI trong lĩnh vực chăm sóc sức khỏe?\n\nTrước tiên, xung đột lợi ích là gì? Trong phạm vi của chúng ta, chúng chỉ tồn tại khi có một lợi ích chính là một nghĩa vụ. Một ví dụ về lợi ích chính là nghĩa vụ của bác sĩ hoặc bệnh viện trong việc chăm sóc bệnh nhân của họ. Tuy nhiên, tất cả chúng ta đều có nhiều lợi ích, một số trong đó có thể cạnh tranh hoặc xung đột với các lợi ích này. Những lợi ích khác này được gọi là lợi ích thứ cấp, và có thể bao gồm, ví dụ, lợi ích tài chính cá nhân hoặc tổ chức, nghĩa vụ đối với người khác như những người không phải là bệnh nhân của bác sĩ hoặc bệnh viện đó, hoặc lợi ích về danh tiếng, dù là tích cực hay tiêu cực.\n\nVậy, tại sao những lợi ích thứ cấp này lại là vấn đề? Trong môi trường chăm sóc sức khỏe, vấn đề phát sinh vì trong quá trình thực hiện nghĩa vụ, nhiều quyết định phải được đưa ra thay mặt cho bệnh nhân, và các quyết định này thường dựa trên đánh giá cá nhân. Và đánh giá này có thể bị ảnh hưởng bởi tất cả các lợi ích thứ cấp đó, theo cách làm lệch khỏi nghĩa vụ chính và gây hại cho bệnh nhân. Một ví dụ về điều này trong chăm sóc lâm sàng là ảnh hưởng của các đại diện bán hàng dược phẩm, những người cố gắng thuyết phục bác sĩ sử dụng thuốc của họ thay vì thuốc của đối thủ, trong khi đôi khi thuốc của đối thủ lại tốt hơn cho bệnh nhân. Ảnh hưởng này có thể được thể hiện dưới dạng ưu đãi tài chính hoặc quà tặng. Những lợi ích thứ cấp này đã được liên kết với những thay đổi đáng kể trong thực hành kê đơn, nên chúng có tác động thực sự. Mặc dù các bác sĩ nghĩ rằng không thể bị ảnh hưởng chỉ bởi một miếng pizza do công ty dược trả tiền, nhưng có một nghiên cứu cho thấy số lượng đơn thuốc có thể tăng hơn gấp đôi chỉ riêng đối với các loại thuốc được cung cấp bữa ăn, so với các loại thuốc tương tự khác, với mức tăng kê đơn được ghi nhận ngay cả sau chỉ một bữa ăn và tăng lên theo từng ngày có thêm bữa ăn được cung cấp.\n\nVì vậy, một phần của vấn đề là các lợi ích thứ cấp này có tác động mà chúng ta không nhận thức được. Trong nghiên cứu y sinh, các lợi ích thứ cấp cũng có thể bao gồm các yếu tố tài chính như hứa hẹn nhận được tài trợ nghiên cứu hoặc phí tư vấn từ các nhà tài trợ, hoặc cổ phiếu hoặc tiền bản quyền từ các công ty có sản phẩm đang được nghiên cứu. Lợi ích thứ cấp cũng có thể là về danh tiếng hoặc ý thức hệ, ví dụ như mong muốn mạnh mẽ được nổi tiếng hoặc thúc đẩy một giả thuyết cụ thể. Trong trường hợp nghiên cứu, lợi ích chính thường là tính liêm chính của nghiên cứu, mặc dù đối với nghiên cứu liên quan đến đối tượng con người, sức khỏe và phúc lợi của từng người tham gia nghiên cứu cũng là ưu tiên cao.\n\nNhưng những tác động tiêu cực có thể có của ảnh hưởng từ lợi ích thứ cấp là gì? Một lần nữa, hãy xem xét tất cả các quyết định được đưa ra trong quá trình nghiên cứu có thể bị lệch khỏi việc phục vụ lợi ích chính là tính liêm chính của nghiên cứu. Một ví dụ là việc xác định câu hỏi nghiên cứu. Câu hỏi đó phục vụ lợi ích của doanh nghiệp hay đáp ứng nhu cầu thực sự của bệnh nhân? Ví dụ, một thử nghiệm lâm sàng được thiết kế để kiểm tra một loại thuốc nhằm phục vụ những bệnh nhân không còn lựa chọn điều trị nào khác, hay chỉ là tái bào chế một loại thuốc hiện có để kéo dài thời gian bảo hộ bằng sáng chế và vị trí thị trường của công ty? Một cách khác mà ảnh hưởng thứ cấp có thể tác động là tạo ra thiên lệch vô thức, dẫn đến đo lường hiệu quả điều trị không chính xác. Chúng ta biết rằng, nói chung, sai số hệ thống có xu hướng làm tăng kích thước hiệu ứng. Các nhà nghiên cứu lâm sàng đã nhận ra điều này từ lâu, và do đó sử dụng các kỹ thuật như ngẫu nhiên hóa và làm mù để giảm thiên lệch, hay sai số hệ thống. Việc lựa chọn sử dụng các kỹ thuật này là các quyết định thiết kế. Các quyết định thiết kế quan trọng khác có thể bị ảnh hưởng bởi lợi ích thứ cấp là chọn đối tượng và dữ liệu nào để nghiên cứu, và cách bạn chọn phân tích, báo cáo hoặc chia sẻ dữ liệu và kết quả.\n\nCác cách giảm thiểu xung đột lợi ích:  \nNguồn: DeJong C, Aguilar T, Tseng C, Lin GA, Boscardin WJ, Dudley RA. Pharmaceutical Industry–Sponsored Meals and Physician Prescribing Patterns for Medicare Beneficiaries. JAMA Intern Med. 2016;176(8)\n\nCông bố  \n• Công khai lợi ích thứ cấp\n\nTrung gian  \n• Đưa lợi ích tài chính (thứ cấp) vào quỹ tín thác mù  \n• Đưa một số quyết định về lợi ích chính vào tay một tổ chức độc lập\n\nTừ chối  \n• Loại bỏ lợi ích tài chính (thứ cấp) hoặc thay thế người có lợi ích chính\n\nVậy, chúng ta làm gì để giảm thiểu tác động tiềm tàng của xung đột lợi ích? Chúng ta có thể tập trung các chiến lược giảm thiểu vào việc bảo vệ lợi ích chính, loại bỏ hoặc giảm lợi ích thứ cấp, hoặc cả hai. Chiến lược phổ biến nhất, mà có lẽ bạn đã từng áp dụng hoặc được yêu cầu áp dụng, là công bố, tức là công khai các lợi ích thứ cấp của bạn, chẳng hạn như công bố phí diễn thuyết hoặc tài trợ nghiên cứu từ các công ty có sản phẩm liên quan đến lợi ích chính. Mặc dù đây là chiến lược phổ biến nhất, nó cũng là yếu nhất vì không làm gì để giảm hoặc loại bỏ lợi ích thứ cấp, mà dựa vào những người được thông báo hiểu được ý nghĩa của việc công bố và hành động theo cách nào đó để chống lại các tác động tiêu cực có thể xảy ra.\n\nCác chiến lược khác mạnh mẽ hơn liên quan đến việc trung gian lợi ích chính hoặc thứ cấp, như đưa lợi ích tài chính vào quỹ tín thác mù, hoặc có một ủy ban giám sát độc lập như Hội đồng Giám sát An toàn Dữ liệu để giám sát hoặc đưa ra các quyết định quan trọng, về cơ bản là loại bỏ quyền kiểm soát của người có xung đột lợi ích. Chiến lược mạnh nhất là từ chối lợi ích thứ cấp, như bán cổ phiếu của mình, hoặc thậm chí từ chối lợi ích chính, như thay thế một nhà nghiên cứu bằng người khác không có xung đột lợi ích.\n\nTHỰC HÀNH ĐẠO ĐỨC TỐT NHẤT – GIẢM THIỂU XUNG ĐỘT LỢI ÍCH\n\nTrong phần này, chúng ta sẽ cố gắng trả lời câu hỏi: làm thế nào để chuyển các chiến lược giảm thiểu xung đột lợi ích sang việc phát triển và triển khai AI cho chăm sóc sức khỏe? Hãy xem xét từng loại chiến lược chung: công bố, trung gian và từ chối.\n\nNguyên tắc cơ bản của công bố là minh bạch, hoặc tạo điều kiện cho những người bị ảnh hưởng bởi AI và những người có nghĩa vụ được chăm sóc biết rằng tồn tại các lợi ích khác có thể ảnh hưởng đến việc chăm sóc này. Đối với AI, sự minh bạch này trở nên phức tạp bởi thực tế là hầu hết những người có thể bị ảnh hưởng, như bệnh nhân và nhà cung cấp dịch vụ, có lẽ thậm chí không biết về sự tồn tại của AI hoặc cách nó có thể được sử dụng trong quyết định về chăm sóc sức khỏe của họ. Vì vậy, trước tiên, một số thông báo công khai về việc sử dụng AI có thể là cần thiết, đặc biệt nếu ứng dụng đó khác biệt đáng kể so với các cách sử dụng dữ liệu thông thường hoặc được chấp nhận trong bối cảnh chăm sóc sức khỏe, hoặc nếu việc sử dụng AI hoặc dữ liệu tiềm ẩn rủi ro cao hơn bình thường hoặc đặc biệt nhạy cảm. Ví dụ có thể là sử dụng và lưu trữ dữ liệu video từ các buổi khám bệnh từ xa, hoặc thu thập và phân tích dữ liệu mạng xã hội của bệnh nhân để dự đoán hoặc chẩn đoán các tình trạng sức khỏe tâm thần, hoặc sử dụng dữ liệu hồ sơ sức khỏe điện tử (EHR), cảm biến và dữ liệu bồi hoàn để hướng dẫn quyết định về việc cung cấp chăm sóc giảm nhẹ vào cuối đời. Thông báo này cũng có thể bao gồm việc công bố cách AI được sử dụng trong quyết định chăm sóc bệnh nhân và ai là người phát triển hệ thống AI đó.\n\nCác cách khác để thực hiện nguyên tắc minh bạch bao gồm báo cáo đầy đủ về cách các mô hình được xây dựng, như các thành viên cộng đồng khoa học dữ liệu đã đề xuất. Điều này bao gồm mô tả rõ ràng về nguồn dữ liệu, đối tượng tham gia, kết quả và biến dự báo, bối cảnh mà mô hình được kiểm định, các hạn chế và chống chỉ định khi triển khai, cũng như các giả định hoặc điều kiện cần được đáp ứng. Hiệp hội Máy tính Hoa Kỳ cũng khuyến nghị rằng đối với các công nghệ nhận diện khuôn mặt, hoặc các ứng dụng AI khác mà thiên lệch chủng tộc hoặc các thiên lệch khác là mối quan tâm, tỷ lệ sai sót nên được báo cáo riêng biệt theo chủng tộc, giới tính và các đặc điểm nhân khẩu học phụ thuộc vào bối cảnh khác.\n\nNguyên tắc đằng sau chiến lược trung gian là đánh giá hoặc giám sát độc lập. Đối với phát triển AI, điều này có thể đạt được bằng cách kiểm toán thuật toán và mô hình bởi bên thứ ba. Quá trình này đã được chính quyền Obama đề xuất năm 2016 để giảm thiểu các thực hành phân biệt đối xử và vi phạm quyền công dân. Việc sử dụng kiểm toán thuật toán cũng tăng cường tính minh bạch ở mức độ khuyến khích các nhà phát triển làm cho thuật toán có thể kiểm toán ngay từ đầu.\n\nChiến lược từ chối trong bối cảnh phát triển AI rất khó thực hiện. Nếu phát triển AI được thực hiện trong môi trường nghiên cứu học thuật, có thể các nhà phát triển sẽ từ chối lợi ích tài chính, hoặc thay thế những người có lợi ích tài chính bằng những người độc lập hơn. Tuy nhiên, trong môi trường doanh nghiệp, điều đó có thể là không thể, nên các nhà phát triển sẽ phải dựa vào các chiến lược dựa trên công bố hoặc trung gian, lưu ý rằng các chiến lược dựa trên công bố rất yếu và ít tạo dựng hoặc duy trì được niềm tin của các bên liên quan chính.\n\nNhững điểm cần ghi nhớ ở đây là:\n• Thực hành đạo đức tốt nhất trong phát triển AI cho chăm sóc sức khỏe bao gồm việc xác định cẩn thận vấn đề cần giải quyết, lý tưởng là với sự đóng góp từ những người có kiến thức sâu về bối cảnh lâm sàng cụ thể và dữ liệu liên quan đến vấn đề.\n• Các lợi ích xung đột có thể có tác động thực sự đến các quyết định thiết kế, nhưng có các chiến lược để giảm thiểu các tác động tiêu cực tiềm tàng của xung đột lợi ích.\n\n---\n\nIf you need the translation to be more concise or formal, feel free to let me know!"
]